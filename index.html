<!DOCTYPE html>
<html
  lang="ru"
  class="scroll-smooth"
>
  <head>
    <meta charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0"
    />
    <title>Теоретический справочник по машинному обучению</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link
      rel="preconnect"
      href="https://fonts.googleapis.com"
    />
    <link
      rel="preconnect"
      href="https://fonts.gstatic.com"
      crossorigin
    />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <script>
      // Конфигурация MathJax для рендеринга математических формул
      window.MathJax = {
        tex: {
          inlineMath: [
            ["$", "$"],
            ["\\(", "\\)"],
          ],
          displayMath: [
            ["$$", "$$"],
            ["\\[", "\\]"],
          ],
        },
        svg: {
          fontCache: "global",
        },
      }
    </script>
    <script
      type="text/javascript"
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"
    ></script>
    <style>
      :root {
        --violet-100: #ede9fe;
        --violet-700: #6d28d9;
        --violet-800: #5b21b6;
        --violet-highlight: rgba(167, 139, 250, 0.2);
        --slate-300: #cbd5e1;
        --slate-400: #94a3b8;
        --slate-500: #64748b;
        --slate-100: #f1f5f9;
        --white: #ffffff;
      }
      body {
        font-family: "Inter", sans-serif;
        background-color: var(--slate-100);
        color: #1e293b; /* slate-800 */
      }
      /* Анимация при переходе по якорю */
      .content-section:target {
        animation: highlight 1.5s ease-out;
      }
      @keyframes highlight {
        from {
          background-color: var(--violet-highlight);
        }
        to {
          background-color: var(--white);
        }
      }
      /* Стили для скроллбара */
      ::-webkit-scrollbar {
        width: 8px;
      }
      ::-webkit-scrollbar-track {
        background: var(--slate-100);
      }
      ::-webkit-scrollbar-thumb {
        background: var(--slate-400);
        border-radius: 10px;
      }
      ::-webkit-scrollbar-thumb:hover {
        background: var(--slate-500);
      }

      /* Стили для заголовков и текста в контенте для лучшей читаемости */
      .content-section h3 {
        font-size: 1.25rem; /* 20px */
        font-weight: 600;
        margin-top: 1.5rem; /* 24px */
        margin-bottom: 0.5rem; /* 8px */
        color: var(--violet-800);
        border-bottom: 1px solid var(--slate-300);
        padding-bottom: 0.25rem;
      }
      .content-section p,
      .content-section ul {
        line-height: 1.65;
        margin-bottom: 1rem;
      }
      .content-section b {
        color: #334155; /* slate-700 */
      }
      /* Стиль для инлайновых блоков кода */
      .content-section code {
        background-color: #f1f5f9; /* slate-100 */
        padding: 0.125rem 0.375rem;
        border-radius: 0.25rem;
        font-family: "Courier New", Courier, monospace;
        font-size: 0.9em;
        color: var(--violet-700);
      }
      /* Стиль для активного пункта в навигации */
      #questionNav .nav-active {
        background-color: var(--violet-100);
        color: var(--violet-800);
        font-weight: 600;
      }
    </style>
  </head>
  <body>
    <!-- 
      Основной контейнер: flex-col для мобильных (стек), md:flex-row для десктопов (рядом)
    -->
    <div class="flex flex-col md:flex-row min-h-screen">
      <!-- Боковая панель (Сайдбар) -->
      <aside
        class="w-full md:w-1/3 lg:w-1/4 md:h-screen md:sticky md:top-0 bg-white shadow-lg flex flex-col"
      >
        <!-- Заголовок и поиск (фиксируются вверху сайдбара) -->
        <div class="p-6 border-b border-slate-200">
          <h1 class="text-2xl font-bold text-violet-700 mb-4">Вопросы по ML</h1>
          <input
            type="text"
            id="searchInput"
            placeholder="Поиск по вопросам..."
            class="w-full p-2 border border-slate-300 rounded-lg focus:ring-2 focus:ring-violet-500 focus:outline-none transition-shadow"
          />
        </div>
        <!-- Навигация (прокручиваемая часть) -->
        <nav
          id="questionNav"
          class="flex-grow p-6 overflow-y-auto"
        >
          <ul class="space-y-1">
            <!-- Ссылки генерируются с помощью JavaScript -->
          </ul>
        </nav>
      </aside>

      <!-- Основной контент -->
      <main class="w-full md:w-2/3 lg:w-3/4 p-6 md:p-10">
        <div
          id="content"
          class="space-y-12"
        >
          <!-- Секции с контентом генерируются с помощью JavaScript -->
        </div>
      </main>
    </div>

    <!-- Кнопка "Наверх" -->
    <button
      id="scrollToTopBtn"
      class="hidden fixed bottom-8 right-8 bg-violet-600 hover:bg-violet-700 text-white p-3 rounded-full shadow-lg transition-all duration-300 hover:scale-110 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-violet-500"
    >
      <svg
        xmlns="http://www.w3.org/2000/svg"
        class="h-6 w-6"
        fill="none"
        viewBox="0 0 24 24"
        stroke="currentColor"
      >
        <path
          stroke-linecap="round"
          stroke-linejoin="round"
          stroke-width="2"
          d="M5 15l7-7 7 7"
        />
      </svg>
    </button>

    <script>
      document.addEventListener("DOMContentLoaded", function () {
        const questions = [
          "1. Понятие машинного обучения. Отличие машинного обучения от других областей программирования.",
          "2. Классификация задач машинного обучения. Примеры задач из различных классов.",
          "3. Основные понятия машинного обучения: набора данных, объекты, признаки, атрибуты, модели, параметры.",
          "4. Структура и представление данных для машинного обучения.",
          "5. Инструментальные средства машинного обучения.",
          "6. Задача регрессии: постановка, математическая формализация.",
          "7. Метод градиентного спуска для парной линейной регрессии.",
          "8. Понятие функции ошибки: требования, использование, примеры.",
          "9. Множественная и нелинейная регрессии.",
          "10. Нормализация признаков в задачах регрессии.",
          "11. Задача классификации: постановка, математическая формализация.",
          "12. Метод градиентного спуска для задач классификации.",
          "13. Логистическая регрессия в задачах классификации.",
          "14. Множественная и многоклассовая классификация. Алгоритм “один против всех”.",
          "15. Метод опорных векторов в задачах классификации.",
          "16. Понятие ядра и виды ядер в методе опорных векторов.",
          "17. Метод решающих деревьев в задачах классификации.",
          "18. Метод k ближайших соседей в задачах классификации.",
          "19. Однослойный перцептрон в задачах классификации.",
          "20. Метрики эффективности и функции ошибки: назначение, примеры, различия.",
          "21. Понятие набора данных (датасета) в машинном обучении. Требования, представление. Признаки и объекты.",
          "22. Шкалы измерения признаков. Виды шкал, их характеристика.",
          "23. Понятие чистых данных. Определение, очистка данных.",
          "24. Основные этапы проекта по машинному обучению.",
          "25. Предварительный анализ данных: задачи, методы, цели.",
          "26. Проблема отсутствующих данных: причины, исследование, пути решения.",
          "27. Проблема несбалансированных классов: исследование, пути решения.",
          "28. Понятие параметров и гиперпараметров модели. Обучение параметров и гиперпараметров. Поиск по сетке.",
          "29. Понятие недо- и переобучения. Определение, пути решения.",
          "30. Диагностика модели машинного обучения. Методы, цели.",
          "31. Проблема выбора модели машинного обучения. Сравнение моделей.",
          "32. Измерение эффективности работы моделей машинного обучения. Метрики эффективности.",
          "33. Метрики эффективности моделей классификации. Виды, характеристика, выбор.",
          "34. Метрики эффективности моделей регрессии. Виды, характеристика, выбор.",
          "35. Перекрестная проверка (кросс-валидация). Назначение, схема работы.",
          "36. Конвейеры в библиотеке sklearn. Назначение, использование.",
          "37. Использование методов визуализации данных для предварительного анализа.",
          "38. Исследование коррелированности признаков: методы, цели, выводы.",
          "39. Решкалирование данных. Виды, назначение, применение. Нормализация и стандартизация данных.",
          "40. Преобразование категориальных признаков в числовые.",
          "41. Методы визуализации данных для машинного обучения.",
          "42. Задача выбора модели. Оценка эффективности, валидационный набор.",
          "43. Кривые обучения для диагностики моделей машинного обучения.",
          "44. Регуляризация моделей машинного обучения. Назначение, виды, формализация.",
          "45. Проблема сбора и интеграции данных для машинного обучения.",
          "46. Понятие чистых данных и требования к данным.",
          "47. Основные задачи описательного анализа данных.",
          "48. Полиномиальные модели машинного обучения.",
          "49. Основные виды преобразования данных для подготовки к машинному обучению.",
          "50. Задача выбора признаков в машинном обучении.",
          "51. Задачи обучения без учителя: общая характеристика, особенности, примеры.",
          "52. Задача кластеризации. Формализация, применение, примеры, общая характеристика. Метрики качества кластеризации.",
          "53. Алгоритм кластеризации K-средних.",
          "54. Иерархическая (агломеративная) кластеризация.",
          "55. Плотностные алгоритмы кластеризации. DBSCAN.",
          "56. Задача понижения размерности в машинном обучении. Метод главных компонент.",
          "57. Алгоритм t-SNE. Общая характеристика, применение, особенности.",
          "58. Задача обнаружения аномалий в машинном обучении. Использование многомерного гауссова распределения.",
          "59. Алгоритм DBSCAN для задач обнаружения аномалий.",
          "60. Ансамбли моделей машинного обучения.",
          "61. Случайный лес как ансамблевая модель.",
          "62. Стекинг как вид ансамблирования моделей. Общая характеристика, особенности.",
          "63. Беггинг как вид ансамблирования моделей. Общая характеристика, особенности.",
          "64. Бустинг как вид ансамблирования моделей. Общая характеристика, особенности.",
          "65. Алгоритм градиентного бустинга. Общая характеристика. LightGBM, XGBoost, CatBoost.",
        ]

        const contents = [
          // Q1
          `<h3>Суть</h3><p>Машинное обучение — это подход, при котором компьютер учится решать задачи, анализируя примеры (данные), а не следуя жёстко прописанным инструкциям.</p><h3>Подробное описание</h3><p><b>Машинное обучение (Machine Learning, ML)</b> представляет собой смену парадигмы в программировании. В <b>классическом программировании</b> человек-разработчик анализирует задачу, разрабатывает алгоритм (чёткую последовательность шагов) и переводит его на язык программирования. Компьютер строго выполняет эти инструкции. Схема выглядит так: <b>Данные + Правила (программа) -> Результат</b>.</p><p>В <b>машинном обучении</b> подход обратный. Мы предоставляем компьютеру большое количество данных и соответствующие им "правильные ответы". Задача алгоритма — самостоятельно найти скрытые в данных закономерности и зависимости, которые связывают входные данные с ответами. Результатом этого процесса является <b>модель</b> — по сути, та же программа с правилами, но эти правила были выведены машиной, а не написаны человеком. Схема здесь такая: <b>Данные + Результаты -> Правила (модель)</b>. Этот подход незаменим для задач, где правила слишком сложны для формализации человеком (например, распознавание лиц) или постоянно меняются (прогноз цен на акции).</p>`,
          // Q2
          `<h3>Суть</h3><p>Задачи ML делятся на три типа: обучение с учителем (учим по размеченным примерам), обучение без учителя (ищем структуру в неразмеченных данных) и обучение с подкреплением (учимся на ошибках, получая "награды" и "штрафы").</p><h3>Подробное описание</h3><p><b>1. Обучение с учителем (Supervised Learning):</b> Самый распространенный класс задач. Алгоритм обучается на датасете, где каждый объект имеет метку (правильный ответ). Цель — научиться предсказывать метки для новых, невиданных ранее объектов.<br>   - <b>Классификация (Classification):</b> Предсказание дискретной метки (категории). <i>Примеры:</i> спам/не спам, тип животного на фото, кредитный скоринг.<br>   - <b>Регрессия (Regression):</b> Предсказание непрерывного числового значения. <i>Примеры:</i> цена квартиры, температура воздуха, спрос на товар.</p><p><b>2. Обучение без учителя (Unsupervised Learning):</b> Алгоритм работает с неразмеченными данными, пытаясь найти в них внутреннюю структуру.<br>   - <b>Кластеризация (Clustering):</b> Группировка схожих объектов. <i>Примеры:</i> сегментация клиентов, группировка новостей по темам.<br>   - <b>Понижение размерности (Dimensionality Reduction):</b> Уменьшение количества признаков с сохранением важной информации. <i>Пример:</i> сжатие данных для визуализации.<br>   - <b>Поиск аномалий (Anomaly Detection):</b> Выявление нетипичных объектов. <i>Пример:</i> обнаружение мошеннических транзакций.</p><p><b>3. Обучение с подкреплением (Reinforcement Learning):</b> Модель (агент) обучается, взаимодействуя со средой. За действия агент получает вознаграждения или штрафы и его цель — выработать стратегию, максимизирующую суммарное вознаграждение. <i>Примеры:</i> обучение роботов ходьбе, игра в шахматы или Go.</p>`,
          // Q3
          `<h3>Суть</h3><p>Данные (набор данных) состоят из объектов (строк) и их признаков (столбцов). Модель — это алгоритм, который после обучения на этих данных, подстроив свои внутренние параметры, может делать предсказания.</p><h3>Подробное описание</h3><ul class="list-disc list-inside space-y-2"><li><b>Набор данных (Dataset):</b> Коллекция данных для обучения и тестирования. Обычно это таблица.</li><li><b>Объект (Sample, Instance):</b> Строка в таблице данных, отдельный пример для анализа (например, один клиент, одно письмо).</li><li><b>Признак (Feature, Attribute):</b> Столбец в таблице, характеристика объекта (например, возраст клиента, длина письма). Признаки — это то, на что смотрит модель.</li><li><b>Модель (Model):</b> Математическая функция, которая принимает на вход признаки объекта и выдает предсказание. Это результат процесса обучения.</li><li><b>Параметры (Parameters):</b> Внутренние переменные модели, которые настраиваются в процессе обучения на данных (например, веса в линейной регрессии). Модель "учится", изменяя свои параметры.</li></ul>`,
          // Q4
          `<h3>Суть</h3><p>Стандартное представление данных для ML — это числовая матрица "объекты-признаки" (X) и, для обучения с учителем, вектор целевых значений (y).</p><h3>Подробное описание</h3><p>Для большинства алгоритмов машинного обучения данные должны быть представлены в виде двух основных структур:<br><b>1. Матрица признаков (X):</b> Это двумерный массив (матрица) размером $m \\times n$, где:<br>   - $m$ — количество объектов (например, пользователей, товаров, изображений).<br>   - $n$ — количество признаков (например, возраст, цена, яркость пикселя).<br>Каждая строка матрицы соответствует одному объекту, а каждый столбец — одному признаку. Все значения в этой матрице должны быть числовыми.<br><b>2. Вектор целевой переменной (y):</b> Это одномерный массив (вектор) длиной $m$. Он используется в задачах обучения с учителем и содержит "правильные ответы" для каждого из $m$ объектов.<br>   - В задачах <b>классификации</b> $y$ содержит метки классов (например, [0, 1, 1, 0]).<br>   - В задачах <b>регрессии</b> $y$ содержит действительные числа (например, [150.5, 230.0, 185.2]).<br>Таким образом, цель обучения — найти зависимость между матрицей $X$ и вектором $y$.</p>`,
          // Q5
          `<h3>Суть</h3><p>Ключевыми инструментами являются язык Python и его библиотеки: NumPy для вычислений, Pandas для работы с данными, Scikit-learn для классического ML, а также TensorFlow и PyTorch для глубокого обучения.</p><h3>Подробное описание</h3><p>Экосистема машинного обучения включает в себя:<br><b>Языки программирования:</b><br>   - <b>Python:</b> Является стандартом де-факто благодаря простоте, огромному сообществу и богатому набору специализированных библиотек.<br>   - <b>R:</b> Популярен в статистике и академических исследованиях.<br><b>Ключевые библиотеки (для Python):</b><br>   - <b>NumPy:</b> Основа для научных вычислений, предоставляет эффективные многомерные массивы.<br>   - <b>Pandas:</b> Незаменима для манипуляций с табличными данными (предоставляет структуру DataFrame).<br>   - <b>Scikit-learn:</b> Наиболее популярная библиотека для классического ML. Содержит готовые реализации большинства алгоритмов, инструментов предобработки и метрик.<br>   - <b>Matplotlib, Seaborn:</b> Библиотеки для визуализации данных.<br>   - <b>TensorFlow, PyTorch:</b> Мощные фреймворки для построения и обучения нейронных сетей (глубокое обучение).<br>   - <b>XGBoost, LightGBM, CatBoost:</b> Высокопроизводительные библиотеки для градиентного бустинга.</p>`,
          // Q6
          `<h3>Суть</h3><p>Задача регрессии — по набору признаков объекта предсказать его числовое значение. Математически это сводится к поиску параметров модели, минимизирующих ошибку предсказания.</p><h3>Подробное описание</h3><p><b>Постановка задачи:</b> Имеется обучающая выборка $\{(x^{(i)}, y^{(i)})\}_{i=1}^m$, где $x^{(i)}$ — вектор признаков $i$-го объекта, а $y^{(i)} \\in \\mathbb{R}$ — соответствующее ему действительное число (целевое значение). Задача — построить модель (функцию, гипотезу) $h(x)$, которая для нового объекта с признаками $x$ будет давать предсказание $\\hat{y} = h(x)$, максимально близкое к истинному значению $y$.<br><b>Математическая формализация:</b> Модель $h$ параметризуется вектором весов $\\theta$. Например, для линейной регрессии $h_{\\theta}(x) = \\theta^T x$. Качество модели оценивается с помощью функции потерь (ошибки) $J(\\theta)$, которая показывает, насколько в среднем предсказания модели отличаются от реальных ответов. Обычно используется среднеквадратичная ошибка (MSE):$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})^2 $$Процесс обучения модели сводится к решению оптимизационной задачи: найти такой вектор параметров $\\theta$, который минимизирует функцию потерь $J(\\theta)$.</p><p><b>Применяемые модели:</b> На практике для задач регрессии используют <b>LinearRegression</b>, <b>Ridge</b>, <b>Lasso</b> (для простых зависимостей и интерпретации), <b>DecisionTreeRegressor</b>, <b>RandomForestRegressor</b> (ансамблевые методы) и, для сложных задач, <b>градиентный бустинг</b> (XGBoost, LightGBM) и <b>нейронные сети</b>.</p>`,
          // Q7
          `<h3>Суть</h3><p>Градиентный спуск — это итеративный метод поиска минимума функции ошибки путем пошагового движения в направлении, противоположном градиенту (направлению наискорейшего роста).</p><h3>Подробное описание</h3><p>Для парной линейной регрессии модель имеет вид $h_{\\theta}(x) = \\theta_0 + \\theta_1 x$. Функция ошибки — $J(\\theta_0, \\theta_1)$. Градиентный спуск — это алгоритм, который помогает найти такие $\\theta_0$ и $\\theta_1$, при которых $J$ минимальна.<br><b>Алгоритм:</b><br>1. Инициализировать $\\theta_0$ и $\\theta_1$ случайными значениями.<br>2. Повторять до сходимости:$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1) \\quad (\\text{для } j=0 \\text{ и } j=1) $$Здесь $\\alpha$ — это скорость обучения (learning rate), гиперпараметр, контролирующий величину шага. $\\frac{\\partial}{\\partial \\theta_j} J$ — это частная производная функции ошибки по параметру $\\theta_j$. Она показывает, как изменится ошибка при небольшом изменении параметра, и задает направление "подъема". Мы движемся в обратном направлении ("антиградиент"), чтобы спускаться.<br>Обновления для $\\theta_0$ и $\\theta_1$ происходят одновременно на каждой итерации. Процесс останавливается, когда значения параметров перестают существенно меняться.</p><p><b>Применение на практике:</b> Градиентный спуск является основным методом оптимизации для большинства моделей в ML, включая линейные модели, логистическую регрессию и, что особенно важно, для обучения <b>глубоких нейронных сетей</b>. Его разновидности (стохастический градиентный спуск, Adam, RMSProp) являются неотъемлемой частью фреймворков, таких как TensorFlow и PyTorch.</p>`,
          // Q8
          `<h3>Суть</h3><p>Функция ошибки (потерь) — это метрика, которая численно показывает, насколько предсказания модели отличаются от реальных ответов. Она используется для оценки и оптимизации модели.</p><h3>Подробное описание</h3><p><b>Функция ошибки (Loss Function / Cost Function)</b> — это ключевой компонент в обучении моделей. Она выполняет две роли:<br>1. <b>Оценка качества:</b> Позволяет измерить, насколько хорошо модель справляется с задачей на данном наборе данных. Чем меньше значение функции ошибки, тем лучше.<br>2. <b>Оптимизация модели:</b> Является основной для алгоритмов оптимизации, таких как градиентный спуск. Минимизируя эту функцию, мы и настраиваем параметры модели.<br><b>Требования к функции ошибки:</b><br>   - Должна быть дифференцируемой (чтобы можно было считать градиенты).<br>   - Желательно, чтобы она была выпуклой, что гарантирует наличие единственного глобального минимума.<br><b>Примеры на практике:</b><br>   - <b>Для регрессии:</b> MSE (Mean Squared Error, среднеквадратичная ошибка), используется в <code>LinearRegression</code>. MAE (Mean Absolute Error, средняя абсолютная ошибка).<br>   - <b>Для классификации:</b> LogLoss (логистическая функция потерь или бинарная кросс-энтропия), используется в <code>LogisticRegression</code>. Hinge Loss (для <code>SVC</code>). Categorical Cross-Entropy для многоклассовой классификации в нейронных сетях.</p>`,
          // Q9
          `<h3>Суть</h3><p>Множественная регрессия использует несколько признаков для предсказания. Нелинейная регрессия использует нелинейные функции (например, полиномы) для описания более сложных зависимостей.</p><h3>Подробное описание</h3><p><b>Множественная (многомерная) линейная регрессия (Multiple Linear Regression)</b> — это расширение парной регрессии на случай, когда для предсказания используется не один, а $n$ признаков ($x_1, x_2, ..., x_n$). Модель (гипотеза) выглядит так:$$ h_{\\theta}(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n $$Она по-прежнему линейна по параметрам $\\theta$, но позволяет улавливать совместное влияние нескольких факторов на целевую переменную.<br><b>Нелинейная регрессия (Non-linear Regression)</b> используется, когда зависимость между признаками и целевой переменной не является линейной. Один из популярных подходов — <b>полиномиальная регрессия</b>. Мы искусственно создаем новые признаки, возводя существующие в степень (например, $x^2, x^3$) или создавая их комбинации ($x_1x_2$). Затем к этим новым признакам применяем обычную линейную регрессию. Например, для одного исходного признака $x$ модель может выглядеть так:$$ h_{\\theta}(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 $$Эта модель является нелинейной по отношению к признаку $x$, но остается линейной по отношению к параметрам $\\theta$, что позволяет использовать для ее обучения те же методы, что и для линейной регрессии.</p><p><b>Применение на практике:</b> Множественная регрессия (<code>LinearRegression</code> в sklearn) — базовый метод для многих задач. Полиномиальная регрессия легко реализуется с помощью <code>PolynomialFeatures</code> в связке с <code>LinearRegression. Для более сложных нелинейных зависимостей на практике применяют <b>деревья решений</b>, <b>случайные леса</b> и <b>градиентный бустинг</b>, которые способны улавливать сложные нелинейные взаимодействия без необходимости явного создания признаков.</p>`,
          // Q10
          `<h3>Суть</h3><p>Нормализация — это приведение признаков к одному масштабу. Это необходимо, чтобы признаки с большими значениями (например, цена в тысячах) не доминировали в процессе обучения над признаками с малыми значениями (например, количество комнат).</p><h3>Подробное описание</h3><p>В задачах регрессии (и многих других задачах ML) алгоритмы, использующие метрики расстояния или градиентный спуск, очень чувствительны к масштабу признаков. Если один признак измеряется в тысячах (например, площадь дома в кв. футах), а другой — в единицах (количество спален), то первый признак будет оказывать гораздо большее влияние на функцию ошибки и на шаги градиентного спуска. Это может замедлить или даже нарушить процесс обучения.<br><b>Нормализация (Feature Scaling)</b> решает эту проблему. Основные методы:<br>1. <b>Min-Max нормализация:</b> Приводит все значения к диапазону [0, 1]. Формула:$$ x'_{norm} = \\frac{x - x_{min}}{x_{max} - x_{min}} $$<br>2. <b>Стандартизация (Z-score):</b> Преобразует данные так, чтобы они имели среднее значение 0 и стандартное отклонение 1. Формула:$$ x'_{std} = \\frac{x - \\mu}{\\sigma} $$где $\\mu$ — среднее, а $\\sigma$ — стандартное отклонение.<br>Стандартизация предпочтительнее, если в данных есть выбросы, так как она не имеет жестких границ [0, 1].</p><p><b>Применение на практике:</b> Нормализация является обязательным шагом предобработки для <b>линейных моделей</b>, <b>SVM</b>, <b>k-NN</b> и <b>нейронных сетей</b>. В "sklearn" для этого используются классы <code>MinMaxScaler</code> и <code>StandardScaler. Модели, основанные на деревьях (Decision Tree, Random Forest, Gradient Boosting), к масштабу признаков нечувствительны.</p>`,
          // Q11
          `<h3>Суть</h3><p>Задача классификации — по набору признаков объекта определить, к какому из заранее известных классов он принадлежит. Математически — найти разделяющую границу между классами.</p><h3>Подробное описание</h3><p><b>Постановка задачи:</b> Имеется обучающая выборка $\{(x^{(i)}, y^{(i)})\}_{i=1}^m$, где $x^{(i)}$ — вектор признаков $i$-го объекта, а $y^{(i)}$ — его метка класса из конечного множества $\{0, 1, ..., K-1\}$. Задача — построить модель (классификатор) $h(x)$, которая для нового объекта с признаками $x$ будет предсказывать его класс $\\hat{y} = h(x)$.<br>   - Если классов два ($y \\in \\{0, 1\\}$), задача называется <b>бинарной классификацией</b>.<br>   - Если классов больше двух, задача называется <b>многоклассовой классификацией</b>.<br><b>Математическая формализация:</b> В отличие от регрессии, модель классификации должна выдавать не число, а метку класса. Часто модели (например, логистическая регрессия) сначала предсказывают вероятность принадлежности объекта к классу "1" — $P(y=1|x; \\theta) \\in [0, 1]$. Затем, на основе этой вероятности, принимается решение о классе, обычно с помощью порогового значения (например, если вероятность > 0.5, то класс 1, иначе — класс 0). Как и в регрессии, обучение сводится к минимизации функции ошибки (например, LogLoss), которая штрафует модель за неверные предсказания вероятностей.</p><p><b>Применяемые модели:</b> На практике для задач классификации используют <b>LogisticRegression</b>, <b>k-Nearest Neighbors (k-NN)</b>, <b>Support Vector Machines (SVM)</b>, <b>DecisionTreeClassifier</b>, <b>RandomForestClassifier</b>, <b>градиентный бустинг</b> (XGBoost, CatBoost) и <b>нейронные сети</b> для сложных данных, таких как изображения и тексты.</p>`,
          // Q12
          `<h3>Суть</h3><p>Градиентный спуск в задачах классификации работает так же, как в регрессии: он итеративно минимизирует функцию ошибки, но сама функция ошибки адаптирована под задачу предсказания вероятностей (например, LogLoss).</p><h3>Подробное описание</h3><p>Принцип градиентного спуска для классификации идентичен его применению в регрессии: это итеративный поиск минимума функции ошибки $J(\\theta)$ путем движения в сторону антиградиента.<br>Ключевое отличие заключается в выборе <b>модели $h_{\\theta}(x)$</b> и <b>функции ошибки $J(\\theta)$</b>.<br>Например, в логистической регрессии моделью является сигмоидальная функция:$$ h_{\\theta}(x) = \\sigma(\\theta^T x) = \\frac{1}{1 + e^{-\\theta^T x}} $$Она преобразует линейную комбинацию признаков в вероятность от 0 до 1.<br>В качестве функции ошибки используется логистическая функция потерь (LogLoss или бинарная кросс-энтропия):$$ J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h_{\\theta}(x^{(i)})) + (1-y^{(i)}) \\log(1 - h_{\\theta}(x^{(i)}))] $$Эта функция штрафует модель, если она предсказывает низкую вероятность для правильного класса и высокую — для неправильного.<br>Далее, как и в регрессии, вычисляются частные производные $\\frac{\\partial}{\\partial \\theta_j} J(\\theta)$ и параметры обновляются по правилу: $\\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta)$.</p><p><b>Применение на практике:</b> Это основной механизм обучения для <b>логистической регрессии</b> и <b>нейронных сетей</b>. В библиотеках 'sklearn', 'TensorFlow', 'PyTorch' он реализован "под капотом" и используется для обучения соответствующих моделей классификации.</p>`,
          // Q13
          `<h3>Суть</h3><p>Логистическая регрессия — это алгоритм классификации, который предсказывает вероятность принадлежности объекта к определённому классу, используя логистическую (сигмоидальную) функцию.</p><h3>Подробное описание</h3><p>Несмотря на слово "регрессия" в названии, логистическая регрессия является методом <b>классификации</b>. Её суть в следующем:<br>1. Сначала, как и в линейной регрессии, вычисляется линейная комбинация признаков и весов: $z = \\theta^T x$.<br>2. Затем результат $z$ (который может быть любым числом от $-\\infty$ до $+\\infty$) пропускается через <b>логистическую функцию (сигмоиду)</b>:$$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$<br>3. Сигмоида "сжимает" любое входное значение в диапазон [0, 1]. Полученное число $h_{\\theta}(x) = \\sigma(\\theta^T x)$ интерпретируется как <b>вероятность</b> того, что объект принадлежит к классу "1".<br>4. Для принятия окончательного решения о классе используется пороговое значение (обычно 0.5). Если $h_{\\theta}(x) \\ge 0.5$, то объект относится к классу 1, иначе — к классу 0.<br>Геометрически логистическая регрессия строит линейную разделяющую границу между классами (прямую для 2-х признаков, плоскость для 3-х и т.д.).</p><p><b>Применение на практике:</b> <code>LogisticRegression</code> из 'sklearn' — это отличная <b>базовая модель (baseline)</b> для задач бинарной классификации. Она быстрая, простая, легко интерпретируемая (можно посмотреть на веса признаков) и часто дает на удивление хорошее качество.</p>`,
          // Q14
          `<h3>Суть</h3><p>Многоклассовая классификация — это задача с более чем двумя классами. "Один против всех" — это метод решения такой задачи, при котором она сводится к нескольким бинарным классификациям.</p><h3>Подробное описание</h3><p><b>Множественная (многоклассовая) классификация (Multiclass Classification)</b> — это задача, в которой объект нужно отнести к одному из $K > 2$ классов. Примеры: распознавание рукописных цифр (10 классов), классификация новостей по темам (спорт, политика, экономика).<br>Многие алгоритмы (например, логистическая регрессия, SVM) изначально разработаны для бинарной классификации. Чтобы применить их к многоклассовым задачам, используют специальные стратегии.<br><b>Алгоритм "Один против всех" (One-vs-Rest, OvR или One-vs-All, OvA):</b><br>1. Для каждого класса $k$ из $K$ классов мы строим отдельный бинарный классификатор.<br>2. Классификатор для класса $k$ обучается на данных, где все объекты класса $k$ считаются положительным классом ("1"), а объекты <b>всех остальных</b> классов — отрицательным ("0").<br>3. Таким образом, мы обучаем $K$ бинарных классификаторов.<br>4. Когда поступает новый объект, мы пропускаем его через все $K$ классификаторов. Каждый из них выдает вероятность принадлежности объекта к "своему" классу.<br>5. Объекту присваивается тот класс, чей классификатор выдал наибольшую вероятность.<br>Существует также метод <b>"Один против одного" (One-vs-One, OvO)</b>, где для каждой пары классов строится свой классификатор.</p><p><b>Применение на практике:</b> Большинство реализаций в "sklearn" (например, <code>LogisticRegression</code>, <code>SVC") автоматически применяют стратегию OvR по умолчанию, если видят, что задача многоклассовая. Пользователю даже не нужно ничего делать специально. Такие модели, как деревья решений, случайный лес и градиентный бустинг, изначально поддерживают многоклассовую классификацию без дополнительных стратегий.</p>`,
          // Q15
          `<h3>Суть</h3><p>Метод опорных векторов (SVM) — это алгоритм классификации, который ищет не просто разделяющую линию, а самую широкую "полосу" между классами. Эта полоса определяется только крайними точками — опорными векторами.</p><h3>Подробное описание</h3><p><b>Метод опорных векторов (Support Vector Machine, SVM)</b> — один из наиболее эффективных классификаторов. Его ключевая идея — найти оптимальную разделяющую гиперплоскость.<br><b>Максимизация зазора (Margin):</b> Вместо того чтобы просто разделить классы, SVM стремится найти такую гиперплоскость, которая находится на максимальном удалении от ближайших точек каждого класса. Это расстояние от гиперплоскости до ближайших точек называется <b>зазором</b>. Интуиция подсказывает, что чем шире зазор, тем лучше обобщающая способность модели и тем она устойчивее к небольшим изменениям в данных.<br><b>Опорные векторы (Support Vectors):</b> Это те объекты обучающей выборки, которые лежат на границах этого самого зазора. Именно они "подпирают" гиперплоскость и определяют ее положение и ширину зазора. Все остальные точки, находящиеся дальше от границы, не влияют на итоговую модель. Это делает SVM эффективным, так как решение зависит лишь от небольшой подвыборки данных.<br><b>Мягкий зазор (Soft Margin):</b> Для данных, которые не являются линейно разделимыми (когда классы перемешаны), SVM позволяет некоторым точкам нарушать границу зазора или даже попадать на чужую территорию. Степень "мягкости" регулируется гиперпараметром $C$, который контролирует компромисс между шириной зазора и количеством ошибок.</p><p><b>Применение на практике:</b> Модели SVM (<code>SVC</code> и <code>LinearSVC</code> в 'sklearn') очень эффективны в пространствах высокой размерности и хорошо работают на небольших и средних датасетах. Они особенно сильны в задачах классификации текстов и на данных, где число признаков велико (например, в биоинформатике).</p>`,
          // Q16
          `<h3>Суть</h3><p>Ядро в SVM — это функция, которая позволяет находить разделяющую границу в пространствах очень высокой размерности без явных вычислений в них. Это позволяет строить нелинейные классификаторы.</p><h3>Подробное описание</h3><p><b>"Трюк с ядром" (Kernel Trick)</b> — это математический прием, который позволяет SVM эффективно работать с нелинейно разделимыми данными. Идея в том, чтобы перевести данные из исходного пространства признаков в пространство более высокой размерности, где они, возможно, станут линейно разделимыми. <br><b>Ядро (Kernel)</b> — это функция, которая вычисляет скалярное произведение векторов в этом новом, высокоразмерном пространстве, но делает это, используя только исходные векторы, без явного преобразования. Это делает вычисления очень эффективными.<br><b>Виды ядер на практике:</b><br> - <b>Линейное (<code>kernel='linear'</code>):</b> Используется для линейно разделимых данных, по сути, обычный SVM.<br> - <b>Полиномиальное (<code>kernel='poly'</code>):</b> Строит полиномиальные границы. Гиперпараметры: степень <code>degree</code>, коэффициент <code>gamma</code>.<br> - <b>Радиальная базисная функция (RBF, <code>kernel='rbf'</code>):</b> Самое популярное ядро, используется по умолчанию в <code>sklearn.svm.SVC</code>. Может создавать очень сложные границы, подходит для большинства задач. Его можно представить как построение границы на основе "близости" к опорным векторам. Ключевой гиперпараметр - <code>gamma</code>.</p>`,
          // Q17
          `<h3>Суть</h3><p>Решающее дерево — это модель, которая классифицирует объекты, задавая последовательность простых вопросов "да/нет" о значениях их признаков.</p><h3>Подробное описание</h3><p><b>Метод решающих деревьев (Decision Trees)</b> — это интуитивно понятный алгоритм, структура которого напоминает блок-схему или дерево. <br><b>Структура:</b><br> - <b>Корень (Root Node):</b> Самый верхний узел, с которого начинается проверка. Он содержит всю обучающую выборку.<br> - <b>Внутренние узлы (Internal Nodes):</b> Каждый узел представляет собой проверку одного из признаков (например, "Возраст < 40?").<br> - <b>Ветви (Branches):</b> Результаты проверки (например, "Да" и "Нет"), ведущие к следующему узлу.<br> - <b>Листья (Leaf Nodes):</b> Конечные узлы дерева, которые содержат решение — метку класса.<br><b>Процесс построения (обучения):</b> Дерево строится сверху вниз. На каждом шаге алгоритм ищет такой признак и такое пороговое значение для него, которое наилучшим образом разделит данные на "чистые" группы (т.е. чтобы в каждой группе было как можно больше объектов одного класса). Качество разделения измеряется с помощью таких критериев, как <b>неопределенность Джини (Gini Impurity)</b> или <b>прирост информации (Information Gain)</b>. Процесс рекурсивно повторяется для каждой новой подгруппы, пока не будет достигнут критерий остановки (например, достигнута максимальная глубина или в узле остались объекты только одного класса).<br><b>Плюсы:</b> Легко интерпретировать ("белый ящик"), не требуют нормализации данных. <br><b>Минусы:</b> Склонны к переобучению, нестабильны (небольшие изменения в данных могут привести к совершенно другому дереву).</p><p><b>Применение на практике:</b> <code>DecisionTreeClassifier</code> и <code>DecisionTreeRegressor</code> из "sklearn". Редко используются в одиночку из-за склонности к переобучению. Чаще всего они служат "строительными блоками" для более мощных ансамблевых моделей, таких как Случайный лес и Градиентный бустинг.</p>`,
          // Q18
          `<h3>Суть</h3><p>Метод k-ближайших соседей (k-NN) классифицирует новый объект на основе "мнения" (классов) его k ближайших соседей из обучающей выборки.</p><h3>Подробное описание</h3><p><b>Метод k ближайших соседей (k-Nearest Neighbors, k-NN)</b> — это один из самых простых "ленивых" алгоритмов классификации. "Ленивый" он потому, что не строит явной модели в процессе обучения. Вместо этого он просто запоминает всю обучающую выборку.<br><b>Алгоритм работы:</b><br>1. Когда поступает новый объект, который нужно классифицировать, алгоритм вычисляет расстояние от этого объекта до <b>каждого</b> объекта в обучающей выборке. В качестве метрики расстояния обычно используется евклидово расстояние.<br>2. Находятся $k$ объектов из обучающей выборки с наименьшим расстоянием до нового объекта (т.е. $k$ его ближайших соседей). $k$ — это гиперпараметр, который задается пользователем.<br>3. Новый объект относится к тому классу, который является самым распространенным среди его $k$ соседей (голосование большинством).<br><b>Особенности:</b><br> - <b>Выбор k:</b> Маленькое $k$ делает модель чувствительной к шуму, большое $k$ — слишком "сглаживает" границы классов.<br> - <b>Проклятие размерности:</b> В пространствах с большим количеством признаков понятие "близости" становится размытым, и k-NN начинает работать плохо.<br> - <b>Вычислительная сложность:</b> На этапе предсказания нужно рассчитать расстояния до всех обучающих примеров, что может быть очень медленно для больших датасетов.</p><p><b>Применение на практике:</b> <code>KNeighborsClassifier</code> и <code>KNeighborsRegressor</code> из "sklearn". Используется как простая базовая модель или в задачах, где важна локальная структура данных, например, в рекомендательных системах ("пользователи, похожие на вас, покупали..."). Требует обязательной нормализации признаков.</p>`,
          // Q19
          `<h3>Суть</h3><p>Однослойный перцептрон — это простейшая модель нейронной сети, представляющая собой один нейрон, который может решать только задачи линейной классификации.</p><h3>Подробное описание</h3><p><b>Однослойный перцептрон</b> (перцептрон Розенблатта) — исторически один из первых алгоритмов для обучения нейронных сетей. Он представляет собой модель одного нейрона, который выполняет следующие шаги:<br>1. Принимает на вход вектор признаков объекта $x = (x_1, ..., x_n)$.<br>2. Вычисляет взвешенную сумму этих признаков с весами $\\theta$: $z = \\sum_{j=1}^{n} \\theta_j x_j + \\theta_0$.<br>3. Применяет к результату пороговую функцию активации (например, ступенчатую функцию): если $z \\ge 0$, выход равен 1, иначе выход равен 0 (или -1 в некоторых реализациях).<br><b>Обучение:</b> Перцептрон обучается итеративно. Если он правильно классифицирует объект, его веса не меняются. Если он ошибается, его веса корректируются таким образом, чтобы "подтолкнуть" взвешенную сумму в правильную сторону. <br><b>Ограничение:</b> Главный недостаток однослойного перцептрона в том, что он может строить только линейную разделяющую границу. Он способен решить только линейно разделимые задачи (например, логическое И, ИЛИ), но не может решить даже простую нелинейную задачу, как XOR (исключающее ИЛИ).</p><p><b>Применение на практике:</b> В современном машинном обучении однослойный перцептрон (<code>Perceptron</code> в "sklearn") практически не используется как самостоятельная модель из-за своих ограничений. Однако он является важным историческим и концептуальным шагом к созданию более сложных <b>многослойных перцептронов</b>, то есть современных нейронных сетей.</p>`,
          // Q20
          `<h3>Суть</h3><p>Функция ошибки используется для обучения модели (её минимизируют), а метрика эффективности — для финальной оценки качества работы модели на тестовых данных, чтобы понять, насколько она хороша с точки зрения бизнес-задачи.</p><h3>Подробное описание</h3><p>Хотя оба понятия оценивают качество модели, у них разные цели.<br><b>Функция ошибки (Loss/Cost Function):</b><br> - <b>Назначение:</b> Основной инструмент для <b>оптимизации</b> модели. Алгоритмы вроде градиентного спуска напрямую работают с ней, пытаясь найти её минимум.<br> - <b>Свойства:</b> Должна быть "удобной" для оптимизатора, т.е. гладкой и дифференцируемой.<br> - <b>Примеры:</b> MSE для регрессии, LogLoss для классификации.<br><b>Метрика эффективности (Performance Metric):</b><br> - <b>Назначение:</b> Инструмент для <b>оценки</b> и <b>сравнения</b> моделей. Она отражает бизнес-цель и понятна человеку. По ней мы принимаем решение, какую модель выбрать для использования.<br> - <b>Свойства:</b> Не обязана быть дифференцируемой. Главное — интерпретируемость.<br> - <b>Примеры:</b> Для классификации — Accuracy (доля правильных ответов), Precision (точность), Recall (полнота), F1-score. Для регрессии — MAE (средняя абсолютная ошибка, понятна, так как в тех же единицах, что и ответ), R² (коэффициент детерминации).<br><b>Различие на примере:</b> Мы можем обучать классификатор, минимизируя LogLoss (функция ошибки), но финальное решение о его качестве принимать на основе метрики Accuracy или F1-score, потому что "доля правильных ответов" или "баланс между точностью и полнотой" более понятны заказчику, чем абстрактное значение логарифмической функции потерь.</p><p><b>Применение на практике:</b> На каждом проекте используются оба понятия. Функции потерь "вшиты" в реализацию моделей, а метрики эффективности активно используются на этапе оценки и выбора лучшей модели (например, в <code>cross_val_score</code> или <code>GridSearchCV</code> параметр "scoring").</p>`,
          // Q21
          `<h3>Суть</h3><p>Датасет — это таблица с данными, где строки — это объекты (например, клиенты), а столбцы — их признаки (например, возраст, доход). Данные должны быть числовыми и структурированными.</p><h3>Подробное описание</h3><p><b>Набор данных (Dataset)</b> — это основное сырье для машинного обучения. Чаще всего он представляет собой структурированную таблицу (матрицу).<br> - <b>Объекты (Objects/Samples):</b> Это строки таблицы. Каждый объект — это независимый пример, который мы анализируем. Это может быть клиент банка, изображение, текст отзыва, молекула и т.д.<br> - <b>Признаки (Features/Attributes):</b> Это столбцы таблицы. Каждый признак — это измеримая характеристика объекта. Например, для объекта "клиент" признаками могут быть "возраст", "пол", "ежемесячный доход", "стаж работы". Совокупность признаков формирует <b>признаковое пространство</b>.<br><b>Требования к данным:</b><br>1. <b>Структурированность:</b> Данные должны быть организованы в виде таблицы "объекты-признаки".<br>2. <b>Числовое представление:</b> Большинство алгоритмов ML работают только с числами. Поэтому категориальные (например, "мужской"/"женский") и текстовые признаки нужно предварительно преобразовать в числа (процесс кодирования).<br>3. <b>Релевантность:</b> Признаки должны содержать информацию, полезную для решения задачи.<br>4. <b>Качество:</b> Данные должны быть как можно более полными (без пропусков) и чистыми (без ошибок и выбросов).</p><p><b>Применение на практике:</b> Для работы с датасетами в Python повсеместно используется библиотека <b>Pandas</b> и ее структура данных <b>DataFrame</b>, которая идеально подходит для представления и манипуляций с табличными данными.</p>`,
          // Q22
          `<h3>Суть</h3><p>Признаки измеряются в разных шкалах (номинальная, порядковая, количественная), и тип шкалы определяет, как мы можем обрабатывать и интерпретировать признак.</p><h3>Подробное описание</h3><p><b>Шкала измерения</b> — это система, которая определяет природу значений признака. Выделяют 4 основных вида:<br>1. <b>Номинальная (Nominal):</b> Значения представляют собой категории, между которыми нет естественного порядка. Можно проверить только на равенство. <i>Примеры:</i> "цвет" (красный, синий), "город" (Москва, Лондон), "пол" (мужской, женский).<br>2. <b>Порядковая (Ordinal):</b> Категории, между которыми есть отношение порядка (больше/меньше), но расстояние между ними не определено. <i>Примеры:</i> "размер одежды" (S, M, L), "уровень образования" (среднее, высшее), "рейтинг" (1, 2, 3, 4, 5 звезд).<br>3. <b>Интервальная (Interval):</b> Числовая шкала, где расстояния между значениями имеют смысл, но нет абсолютного нуля. <i>Примеры:</i> "температура в градусах Цельсия" (0°C не означает отсутствие тепла), "год" (0 год — условная точка).<br>4. <b>Отношений (Ratio):</b> Числовая шкала, где есть абсолютный ноль, означающий полное отсутствие измеряемой величины. <i>Примеры:</i> "возраст", "доход", "вес", "рост".</p><p><b>Применение на практике:</b> Тип шкалы определяет метод кодирования. Номинальные признаки кодируют через <b>One-Hot Encoding</b> (<code>OneHotEncoder</code>, <code>pd.get_dummies</code>). Порядковые — через целочисленное кодирование с сохранением порядка (<code>OrdinalEncoder</code>). Количественные (интервальные и отношений) обычно используются как есть, но часто требуют <b>нормализации</b> или <b>стандартизации</b>.</p>`,
          // Q23
          `<h3>Суть</h3><p>Чистые данные ("Tidy data") — это стандарт организации данных в таблицу, где каждая строка — это наблюдение, каждый столбец — переменная, что упрощает их анализ и обработку.</p><h3>Подробное описание</h3><p>Концепция <b>"чистых данных" (Tidy Data)</b>, популяризированная Хедли Уикхемом, предполагает строгое соответствие структуры данных их семантике. Есть три основных правила:<br>1. Каждая переменная (признак) формирует столбец.<br>2. Каждое наблюдение (объект) формирует строку.<br>3. Каждый тип наблюдаемого объекта формирует отдельную таблицу.<br><b>Очистка данных (Data Cleaning)</b> — это процесс приведения "грязных", сырых данных к чистому виду. Он включает в себя:<br> - <b>Обработку пропусков:</b> Заполнение или удаление отсутствующих значений.<br> - <b>Исправление ошибок:</b> Корректировка опечаток, неконсистентных записей (например, "РФ" и "Россия").<br> - <b>Обработку выбросов:</b> Удаление или трансформация аномально больших или малых значений.<br> - <b>Приведение типов:</b> Преобразование столбцов к нужным типам (например, строка "123" в число 123).<br> - <b>Структурные преобразования:</b> Изменение формы таблицы (например, сводные таблицы) для приведения к "чистому" формату.</p><p><b>Применение на практике:</b> Очистка данных — один из самых трудоемких этапов ML-проекта. Основным инструментом для этого в Python является библиотека <b>Pandas</b>, предоставляющая мощные средства для фильтрации, преобразования, заполнения пропусков (<code>.fillna()</code>), удаления дубликатов (<code>.drop_duplicates()</code>) и многого другого.</p>`,
          // Q24
          `<h3>Суть</h3><p>Типичный ML-проект — это итеративный процесс, включающий понимание задачи, сбор и подготовку данных, создание и оценку модели, и, наконец, ее внедрение.</p><h3>Подробное описание</h3><p>Жизненный цикл проекта по машинному обучению часто описывается методологией <b>CRISP-DM (Cross-Industry Standard Process for Data Mining)</b>, которая включает следующие этапы:<br>1. <b>Понимание бизнеса (Business Understanding):</b> Определение целей проекта, бизнес-метрик успеха. Что мы хотим предсказать и зачем? Как это поможет бизнесу?<br>2. <b>Понимание данных (Data Understanding):</b> Сбор исходных данных, их изучение, описание, первичный анализ (EDA) для выявления закономерностей и проблем.<br>3. <b>Подготовка данных (Data Preparation):</b> Самый трудоемкий этап. Включает очистку данных, обработку пропусков, кодирование категориальных признаков, нормализацию, генерацию новых признаков (feature engineering).<br>4. <b>Моделирование (Modeling):</b> Выбор и обучение одной или нескольких ML-моделей. На этом этапе подбираются гиперпараметры моделей.<br>5. <b>Оценка (Evaluation):</b> Оценка качества моделей с помощью технических метрик (Accuracy, F1, MSE и т.д.) на отложенной выборке. Важно проверить, соответствует ли результат целям, поставленным на первом этапе.<br>6. <b>Внедрение (Deployment):</b> "Упаковка" лучшей модели и интеграция ее в рабочую систему (например, в виде API-сервиса). После внедрения необходим постоянный мониторинг производительности модели на реальных данных.</p><p><b>На практике</b> эти этапы нелинейны. Часто приходится возвращаться с этапа моделирования к подготовке данных, чтобы сгенерировать новые признаки, или с этапа оценки к пониманию бизнеса, чтобы скорректировать цели.</p>`,
          // Q25
          `<h3>Суть</h3><p>Предварительный анализ данных (EDA) — это исследование датасета с целью понять его структуру, найти закономерности, аномалии и сформулировать гипотезы для дальнейшего моделирования.</p><h3>Подробное описание</h3><p><b>Предварительный (или разведочный) анализ данных (Exploratory Data Analysis, EDA)</b> — это критически важный первый шаг в работе с любым набором данных.<br><b>Задачи EDA:</b><br> - Получить общее представление о данных: размерность, типы признаков, количество пропусков.<br> - Рассчитать основные описательные статистики для каждого признака (среднее, медиана, стандартное отклонение, минимум, максимум).<br> - Визуализировать распределение каждого признака (гистограммы для числовых, столбчатые диаграммы для категориальных).<br> - Исследовать взаимосвязи между признаками (корреляционные матрицы, диаграммы рассеяния).<br> - Обнаружить выбросы, аномалии и другие проблемы в данных.<br> - Сформулировать гипотезы о данных, которые можно будет проверить с помощью моделей.<br><b>Методы:</b> Основные методы EDA — это расчет описательных статистик и визуализация.<br><b>Цели:</b> Главная цель — глубоко "почувствовать" данные перед тем, как применять к ним сложные алгоритмы. Качественный EDA позволяет выбрать правильные методы предобработки, сгенерировать полезные признаки и избежать грубых ошибок при моделировании.</p><p><b>Применение на практике:</b> EDA выполняется с помощью библиотек <b>Pandas</b> (для расчета статистик: <code>.describe()</code>, <code>.info()</code>, <code>.value_counts()</code>) и <b>Matplotlib/Seaborn</b> (для построения графиков: гистограмм, диаграмм рассеяния, тепловых карт корреляции).</p>`,
          // Q26
          `<h3>Суть</h3><p>Отсутствующие данные — это распространенная проблема, которую решают либо удалением неполных данных, либо их заполнением (импутацией) на основе имеющейся информации.</p><h3>Подробное описание</h3><p><b>Причины отсутствующих данных:</b> Ошибки при сборе, отказ пользователя предоставлять информацию, технические сбои.<br><b>Пути решения:</b><br>1. <b>Удаление:</b><br>   - <b>Удаление строк (Listwise deletion):</b> Самый простой метод. Удаляются все объекты, у которых есть хотя бы один пропуск. Эффективно, только если пропусков очень мало, иначе теряется много данных.<br>   - <b>Удаление столбцов:</b> Удаляется признак целиком, если в нем слишком много пропусков (например, >50%).<br>2. <b>Заполнение (Импутация):</b><br>   - <b>Простое заполнение:</b> Замена пропусков на одно и то же значение: среднее (<code>mean</code>), медиану (<code>median</code>) или моду (<code>most_frequent</code>). Медиана более устойчива к выбросам, чем среднее.<br>   - <b>Заполнение на основе модели:</b> Пропуски в признаке рассматриваются как целевая переменная, и строится модель (например, регрессия), которая предсказывает их на основе других признаков.<br>   - <b>KNN-импутация:</b> Пропуски заполняются средним значением среди $k$ ближайших соседей этого объекта.</p><p><b>Применение на практике:</b> В "sklearn.impute" есть готовые инструменты: <code>SimpleImputer</code> для простого заполнения, <code>KNNImputer</code> для метода ближайших соседей и <code>IterativeImputer</code> для сложного модельного заполнения (аналог MICE).</p>`,
          // Q27
          `<h3>Суть</h3><p>Несбалансированные классы — это ситуация, когда объектов одного класса значительно больше, чем другого. Это мешает модели учиться, и для решения проблемы применяют изменение выборки или специальные метрики.</p><h3>Подробное описание</h3><p><b>Проблема:</b> В задачах классификации часто встречается ситуация, когда один класс (мажоритарный) представлен гораздо большим количеством примеров, чем другой (миноритарный). <i>Примеры:</i> выявление мошеннических транзакций (99.9% — норма, 0.1% — фрод), диагностика редких заболеваний.<br>Если обучать модель на таких данных "в лоб", она может достичь высокой точности (Accuracy), просто предсказывая всегда мажоритарный класс. Например, модель, которая всегда говорит "не фрод", будет права в 99.9% случаев, но будет абсолютно бесполезна на практике.<br><b>Пути решения:</b><br>1. <b>Изменение выборки (Resampling):</b><br>   - <b>Oversampling (увеличение минорного класса):</b> Создание копий объектов минорного класса. Более продвинутый метод — <b>SMOTE (Synthetic Minority Over-sampling Technique)</b>, который генерирует новые, синтетические примеры минорного класса на основе его соседей.<br>   - <b>Undersampling (уменьшение мажорного класса):</b> Случайное удаление объектов мажорного класса до достижения баланса. Может привести к потере важной информации.<br>2. <b>Использование правильных метрик:</b> Вместо Accuracy нужно использовать <b>Precision, Recall, F1-score, AUC-ROC, AUC-PR</b>, которые не зависят от баланса классов.<br>3. <b>Взвешивание классов:</b> Назначить больший "штраф" за ошибку на объектах минорного класса в функции потерь модели.</p><p><b>Применение на практике:</b> Для ресемплинга используется библиотека <b>imbalanced-learn</b> с реализацией <code>SMOTE". Для взвешивания классов в моделях "sklearn" (например, <code>LogisticRegression</code>, <code>RandomForestClassifier") есть параметр <code>class_weight='balanced'</code>. </p>`,
          // Q28
          `<h3>Суть</h3><p>Параметры — это то, что модель выучивает из данных сама (например, веса). Гиперпараметры — это "настройки" модели, которые мы задаем до обучения (например, скорость обучения). Поиск по сетке — это способ найти лучшие гиперпараметры.</p><h3>Подробное описание</h3><p><b>Параметры модели:</b> Это внутренние переменные, значения которых подбираются алгоритмом в процессе обучения. Они являются результатом обучения. Мы не задаем их вручную. <i>Примеры:</i> веса $\\theta$ в линейной или логистической регрессии, веса и смещения в нейронной сети.<br><b>Гиперпараметры модели:</b> Это внешние настройки, которые мы, как инженеры, задаем перед началом процесса обучения. Они определяют, как именно модель будет учиться. От их выбора сильно зависит итоговое качество модели. <i>Примеры:</i><br>   - Скорость обучения $\\alpha$ в градиентном спуске.<br>   - Количество соседей $k$ в k-NN.<br>   - Коэффициент регуляризации $C$ или $\\lambda$.<br>   - Максимальная глубина дерева в <code>DecisionTree</code>.<br>   - Количество деревьев в <code>RandomForest".<br><b>Подбор гиперпараметров:</b> Поскольку оптимальные значения заранее неизвестны, их подбирают, пробуя разные комбинации.<br>   - <b>Поиск по сетке (Grid Search):</b> Мы задаем сетку возможных значений для каждого гиперпараметра. Алгоритм перебирает <b>все возможные комбинации</b> и для каждой обучает и оценивает модель (обычно с помощью кросс-валидации). Выбирается комбинация с лучшим качеством. Очень медленный, если гиперпараметров много.<br>   - <b>Случайный поиск (Random Search):</b> Перебирает не все комбинации, а заданное количество случайных. Часто находит почти такие же хорошие гиперпараметры, но гораздо быстрее.</p><p><b>Применение на практике:</b> В "sklearn" для этого есть классы <code>GridSearchCV</code> и <code>RandomizedSearchCV</code>, которые автоматизируют процесс подбора.</p>`,
          // Q29
          `<h3>Суть</h3><p>Недообучение — модель слишком проста и не улавливает закономерности. Переобучение — модель слишком сложна и выучивает шум. Решение — подбор оптимальной сложности модели и регуляризация.</p><h3>Подробное описание</h3><p>Это две центральные проблемы в ML, связанные с компромиссом между смещением (bias) и разбросом (variance).<br><b>Недообучение (Underfitting, высокое смещение):</b><br> - <b>Что это?</b> Модель слишком проста, чтобы уловить основные зависимости в данных. Она показывает плохую производительность и на обучающей, и на тестовой выборке.<br> - <b>Пути решения:</b> Усложнить модель (взять полином большей степени, более глубокое дерево, более сложную нейросеть), добавить новые признаки, уменьшить регуляризацию.<br><b>Переобучение (Overfitting, высокий разброс):</b><br> - <b>Что это?</b> Модель слишком сложная и "запоминает" не только закономерности, но и случайный шум в обучающих данных. Она показывает отличную производительность на обучающей выборке, но проваливается на новых (тестовых) данных.<br> - <b>Пути решения:</b><br>   1. <b>Собрать больше данных:</b> Самый надежный способ.<br>   2. <b>Регуляризация:</b> "Штраф" за сложность модели (L1, L2, Dropout).<br>   3. <b>Упростить модель:</b> Уменьшить сложность (глубину дерева, количество нейронов).<br>   4. <b>Отбор признаков:</b> Убрать ненужные признаки.<br>   5. <b>Ранняя остановка (Early Stopping):</b> Остановить обучение, как только качество на валидационной выборке перестает улучшаться.</p><p><b>Применение на практике:</b> Борьба с переобучением — ежедневная задача ML-инженера. Активно используются <b>регуляризация</b> (параметры "alpha" или "C" в моделях "sklearn"), <b>Dropout</b>-слои в нейросетях ("keras", "pytorch"), а также <b>кросс-валидация</b> для надежной оценки склонности к переобучению.</p>`,
          // Q30
          `<h3>Суть</h3><p>Диагностика модели — это процесс анализа ее поведения, чтобы понять, страдает ли она от недо/переобучения и как можно улучшить ее производительность. Основной инструмент — кривые обучения.</p><h3>Подробное описание</h3><p><b>Диагностика модели</b> — это набор методов, позволяющих понять, почему модель работает так, а не иначе, и что с этим делать. Это не просто измерение метрики, а анализ причин.<br><b>Цели:</b><br> - Определить, страдает ли модель от высокого смещения (недообучение) или высокого разброса (переобучение).<br> - Понять, поможет ли сбор большего количества данных, добавление новых признаков или изменение сложности модели.<br><b>Методы:</b><br>1. <b>Кривые обучения (Learning Curves):</b> Это график, показывающий зависимость ошибки (или метрики) на обучающей и валидационной выборках от количества обучающих примеров. Анализируя расхождение и наклон этих кривых, можно диагностировать недо/переобучение.<br>2. <b>Кривые валидации (Validation Curves):</b> Это график зависимости ошибки от значения какого-либо гиперпараметра (например, глубины дерева). Он помогает найти оптимальное значение для этого гиперпараметра.<br>3. <b>Анализ ошибок (Error Analysis):</b> Ручное исследование примеров, на которых модель ошибается. Это помогает понять, в каких ситуациях модель слаба, и сгенерировать новые идеи для улучшения (например, создать новые признаки).</p><p><b>Применение на практике:</b> В "sklearn" есть готовые функции <code>learning_curve</code> и <code>validation_curve", которые позволяют легко строить диагностические графики. Анализ ошибок — это более ручной процесс, часто с использованием "pandas" для фильтрации и изучения неверных предсказаний.</p>`,
          // Q31
          `<h3>Суть</h3><p>Выбор модели — это процесс сравнения нескольких обученных алгоритмов на основе их производительности на отложенных данных, чтобы найти лучший для конкретной задачи.</p><h3>Подробное описание</h3><p>Редко бывает так, что для задачи подходит только один алгоритм. Обычно пробуют несколько разных подходов. Проблема выбора модели состоит из нескольких шагов:<br>1. <b>Формирование пула кандидатов:</b> Выбор нескольких подходящих алгоритмов (например, Логистическая регрессия, Случайный лес, Градиентный бустинг).<br>2. <b>Настройка гиперпараметров:</b> Для каждого кандидата подбираются оптимальные гиперпараметры (например, с помощью <code>GridSearchCV</code>).<br>3. <b>Сравнение моделей:</b> Лучшие версии каждого алгоритма сравниваются между собой. Сравнение должно проводиться на <b>отложенной тестовой выборке</b>, которую модели еще не видели. Качество оценивается по ключевой для бизнеса метрике (F1-score, MAE и т.д.).<br>4. <b>Статистическая значимость:</b> Желательно убедиться, что превосходство одной модели над другой не является случайным (например, с помощью статистических тестов).<br>5. <b>Учет других факторов:</b> Помимо метрик, учитывается скорость предсказания, интерпретируемость модели, сложность внедрения и поддержки.</p><p><b>Применение на практике:</b> Часто создается "шорт-лист" из 2-3 моделей. Например, простая и интерпретируемая <code>LogisticRegression</code> как baseline, <code>RandomForestClassifier</code> как надежный середнячок и <code>XGBoost</code> или <code>LightGBM" как тяжелая артиллерия. Выбор делается на основе компромисса между качеством и сложностью.</p>`,
          // Q32
          `<h3>Суть</h3><p>Эффективность модели измеряется с помощью специальных метрик, которые численно показывают, насколько хорошо она решает поставленную задачу (например, как часто она угадывает класс или насколько близки ее числовые предсказания к реальным).</p><h3>Подробное описание</h3><p><b>Метрики эффективности</b> — это стандартизированные способы измерения производительности модели. Они необходимы для:<br> - <b>Объективного сравнения моделей:</b> Позволяют понять, какая из моделей лучше.<br> - <b>Подбора гиперпараметров:</b> Используются внутри <code>GridSearchCV" для выбора лучшей комбинации.<br> - <b>Оценки бизнес-эффекта:</b> Помогают перевести качество модели на язык бизнеса (например, "мы можем правильно определять 95% мошеннических операций").<br>Выбор метрики зависит от типа задачи и ее особенностей.<br> - <b>Для регрессии</b> метрики измеряют среднюю ошибку предсказания.<br> - <b>Для классификации</b> метрики оценивают, как хорошо модель разделяет классы.<br> - <b>Для кластеризации</b> метрики оценивают компактность и разделенность кластеров.</p><p><b>Применение на практике:</b> Модуль "sklearn.metrics" содержит реализации десятков метрик. Самые популярные: <code>accuracy_score</code>, <code>precision_score</code>, <code>recall_score</code>, <code>f1_score</code>, <code>roc_auc_score</code> для классификации; <code>mean_squared_error</code>, <code>mean_absolute_error", <code>r2_score</code> для регрессии.</p>`,
          // Q33
          `<h3>Суть</h3><p>В классификации ключевыми метриками являются Accuracy, Precision, Recall и F1-score. Выбор зависит от того, какая ошибка для нас страшнее: ложноположительная или ложноотрицательная.</p><h3>Подробное описание</h3><p>Метрики классификации строятся на основе <b>матрицы ошибок (Confusion Matrix)</b>, которая содержит 4 значения: True Positive (TP), False Positive (FP), True Negative (TN), False Negative (FN).<br><b>Основные метрики:</b><br> - <b>Accuracy (Доля правильных ответов):</b> $(TP+TN)/(TP+FP+TN+FN)$. Доля всех верных предсказаний. <b>Не подходит для несбалансированных классов.</b><br> - <b>Precision (Точность):</b> $TP/(TP+FP)$. Доля объектов, которые модель назвала положительными, и они действительно являются таковыми. Отвечает на вопрос "Насколько можно доверять положительным предсказаниям?". Важна, когда цена ошибки FP высока (например, спам-фильтр).<br> - <b>Recall (Полнота):</b> $TP/(TP+FN)$. Доля реальных положительных объектов, которые модель смогла обнаружить. Отвечает на вопрос "Насколько хорошо модель находит все положительные объекты?". Важна, когда цена ошибки FN высока (например, диагностика рака).<br> - <b>F1-score:</b> $2 * (Precision * Recall) / (Precision + Recall)$. Гармоническое среднее между точностью и полнотой. Используется, когда важен баланс между этими двумя метриками.<br> - <b>ROC AUC:</b> Площадь под ROC-кривой. Показывает, насколько хорошо модель в целом умеет разделять классы, независимо от порога классификации. Значение 0.5 — случайное угадывание, 1.0 — идеальный классификатор.</p><p><b>Применение на практике:</b> Выбор метрики — это бизнес-решение. Для диагностики болезней важнее Recall. Для email-рассылок (не отправить нецелевое письмо) — Precision. Если баланс важен, используют F1-score. ROC AUC часто используется для общего сравнения моделей.</p>`,
          // Q34
          `<h3>Суть</h3><p>В регрессии эффективность измеряется средней ошибкой между предсказанными и реальными числовыми значениями. Основные метрики — MAE, MSE, R².</p><h3>Подробное описание</h3><p><b>Основные метрики:</b><br> - <b>MAE (Mean Absolute Error, Средняя абсолютная ошибка):</b> $\\frac{1}{m} \\sum |y_i - \\hat{y}_i|$. Показывает среднее абсолютное отклонение предсказаний от факта. Легко интерпретируется, так как измеряется в тех же единицах, что и целевая переменная.<br> - <b>MSE (Mean Squared Error, Среднеквадратичная ошибка):</b> $\\frac{1}{m} \\sum (y_i - \\hat{y}_i)^2$. Сильнее штрафует за большие ошибки из-за возведения в квадрат. Часто используется как функция потерь при обучении.<br> - <b>RMSE (Root Mean Squared Error):</b> $\\sqrt{MSE}$. Корень из MSE. Тоже измеряется в тех же единицах, что и целевая переменная, но сохраняет свойство сильного штрафа за большие ошибки.<br> - <b>R² (Коэффициент детерминации):</b> $1 - \\frac{\\sum(y_i - \\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2}$. Показывает, какую долю дисперсии целевой переменной объясняет наша модель. Значение 1.0 означает, что модель идеально объясняет данные. Значение 0 означает, что модель работает не лучше, чем простое предсказание среднего значения. Может быть отрицательным, если модель очень плохая.</p><p><b>Применение на практике:</b> MAE используют, когда хотят понятную бизнесу оценку средней ошибки. RMSE — когда большие ошибки особенно нежелательны. R² — для оценки общей объясняющей силы модели.</p>`,
          // Q35
          `<h3>Суть</h3><p>Кросс-валидация — это метод оценки качества модели, при котором данные многократно делятся на обучающую и тестовую части, чтобы получить более надежную и стабильную оценку, чем при единичном разбиении.</p><h3>Подробное описание</h3><p>Оценка модели на одном-единственном тестовом наборе может быть случайной: нам могло повезти или не повезти с разбиением. Кросс-валидация решает эту проблему.<br><b>Схема работы (K-Fold Cross-Validation):</b><br>1. Весь набор данных (кроме отложенного тестового) делится на $K$ равных частей (блоков или "фолдов"), например, на 5.<br>2. Запускается цикл из $K$ итераций:<br>   - На итерации $i$, $i$-й блок используется как <b>валидационный</b> (тестовый).<br>   - Остальные $K-1$ блоков объединяются и используются для <b>обучения</b> модели.<br>   - Модель обучается на обучающих блоках и оценивается на валидационном. Метрика качества сохраняется.<br>3. После $K$ итераций мы получаем $K$ оценок качества. Финальная оценка — это их среднее значение. Оно гораздо более робастно (устойчиво), чем оценка от одного разбиения.<br><b>Stratified K-Fold:</b> Вариация для задач классификации, которая следит за тем, чтобы в каждом фолде сохранялось исходное соотношение классов. Это обязательно для несбалансированных данных.</p><p><b>Применение на практике:</b> Кросс-валидация — стандарт индустрии для оценки моделей и подбора гиперпараметров. В "sklearn" используется через функции <code>cross_val_score</code>, <code>cross_validate</code>, а также встроена по умолчанию в <code>GridSearchCV</code> и <code>RandomizedSearchCV".</p>`,
          // Q36
          `<h3>Суть</h3><p>Конвейеры (Pipelines) в sklearn позволяют объединить несколько шагов обработки данных и моделирования в один единый объект, что делает код чище и безопаснее.</p><h3>Подробное описание</h3><p>Процесс машинного обучения часто состоит из последовательности шагов: заполнение пропусков, кодирование признаков, нормализация, обучение модели. Выполнять эти шаги по отдельности для обучающей и тестовой выборок — рискованно, можно легко допустить ошибку (например, "подсмотреть" в тестовые данные при расчете среднего для нормализации).<br><b>Конвейер (<code>Pipeline</code>)</b> решает эту проблему. Он позволяет "упаковать" все шаги в один объект, который ведет себя как обычная модель.<br><b>Назначение и преимущества:</b><br>1. <b>Предотвращение утечки данных (Data Leakage):</b> <code>Pipeline</code> гарантирует, что все шаги предобработки на каждом шаге кросс-валидации обучаются только на обучающей части данных и лишь применяются к валидационной. Это правильный и безопасный способ.<br>2. <b>Удобство:</b> Вместо вызова <code>.fit_transform()</code> на трейне и <code>.transform()</code> на тесте для каждого шага, вы просто вызываете <code>.fit()</code> и <code>.predict()</code> для всего пайплайна.<br>3. <b>Воспроизводимость:</b> Весь воркфлоу (предобработка + модель) хранится в одном объекте, который легко сохранить и использовать.<br>4. <b>Подбор гиперпараметров:</b> <code>GridSearchCV</code> может подбирать гиперпараметры не только модели, но и шагов предобработки внутри пайплайна.</p><p><b>Применение на практике:</b> <code>Pipeline</code> из <code>sklearn.pipeline</code> является обязательным инструментом в любом серьезном ML проекте. Он используется для объединения трансформеров (например, <code>SimpleImputer</code>, <code>StandardScaler</code>, <code>OneHotEncoder") и финальной модели (например, <code>LogisticRegression</code>). <code>ColumnTransformer</code> позволяет применять разные шаги к разным колонкам внутри одного пайплайна.</p>`,
          // Q37
          `<h3>Суть</h3><p>Визуализация на этапе предварительного анализа помогает наглядно исследовать данные: понять распределения признаков, выявить взаимосвязи, найти аномалии и выбросы.</p><h3>Подробное описание</h3><p>Визуализация — это мощнейший инструмент для понимания данных, так как человеческий мозг гораздо лучше воспринимает картинки, чем таблицы с числами. <br><b>Основные типы графиков для EDA:</b><br> - <b>Гистограммы и графики плотности (Histograms, KDE plots):</b> Показывают распределение одного числового признака. Позволяют увидеть, является ли оно нормальным, есть ли несколько "пиков" (мод), насколько оно скошено.<br> - <b>Столбчатые диаграммы (Bar charts):</b> Показывают частоту каждой категории для категориального признака.<br> - <b>Диаграммы рассеяния (Scatter plots):</b> Показывают взаимосвязь между двумя числовыми признаками. Помогают увидеть линейные или нелинейные зависимости, кластеры.<br> - <b>Ящики с усами (Box plots):</b> Компактно показывают распределение числового признака: медиану, квартили и выбросы.<br> - <b>Тепловые карты корреляции (Correlation Heatmaps):</b> Показывают матрицу корреляций Пирсона для всех пар числовых признаков. Помогают быстро найти сильно связанные переменные.</p><p><b>Применение на практике:</b> Для построения этих графиков в Python используются библиотеки <b>Matplotlib</b> (для базовых и кастомных графиков) и <b>Seaborn</b> (для более сложных и эстетичных статистических графиков). Например, <code>seaborn.histplot</code>, <code>seaborn.scatterplot</code>, <code>seaborn.boxplot</code>, <code>seaborn.heatmap".</p>`,
          // Q38
          `<h3>Суть</h3><p>Исследование корреляции признаков помогает найти линейные взаимосвязи между ними. Это нужно для отбора признаков, предотвращения проблем в моделях и лучшего понимания данных.</p><h3>Подробное описание</h3><p><b>Корреляция</b> — это статистическая мера, показывающая степень линейной взаимосвязи между двумя переменными. Чаще всего используется <b>коэффициент корреляции Пирсона</b>, который принимает значения от -1 до +1:<br> - <b>+1:</b> Идеальная положительная линейная связь (одна переменная растет, вторая тоже).<br> - <b>-1:</b> Идеальная отрицательная линейная связь (одна растет, вторая падает).<br> - <b>0:</b> Отсутствие линейной связи.<br><b>Цели исследования:</b><br>1. <b>Отбор признаков:</b> Если два признака очень сильно коррелируют друг с другом (например, > 0.9), они несут почти одинаковую информацию (избыточны). Один из них можно удалить, чтобы уменьшить сложность модели. Это называется проблемой <b>мультиколлинеарности</b>.<br>2. <b>Понимание данных:</b> Поиск признаков, которые сильно коррелируют с целевой переменной. Это хорошие кандидаты для модели.<br><b>Методы:</b><br> - Расчет матрицы корреляций для всех пар числовых признаков.<br> - Визуализация этой матрицы с помощью тепловой карты (heatmap).<br><b>Выводы:</b> Наличие сильной корреляции между признаками может ухудшить устойчивость и интерпретируемость линейных моделей. Для древовидных моделей это менее критично.</p><p><b>Применение на практике:</b> В pandas DataFrame матрицу корреляций можно легко посчитать методом <code>.corr()</code>. Затем ее визуализируют с помощью <code>seaborn.heatmap()"".</p>`,
          // Q39
          `<h3>Суть</h3><p>Решкалирование — это приведение числовых признаков к общему масштабу. Нормализация сжимает данные в диапазон [0, 1], а стандартизация приводит к среднему 0 и стандартному отклонению 1.</p><h3>Подробное описание</h3><p><b>Решкалирование (Feature Scaling)</b> — это общее название для методов преобразования масштаба признаков. Это необходимо для алгоритмов, которые чувствительны к масштабу (линейные модели, SVM, k-NN, нейросети).<br><b>Виды и назначение:</b><br>1. <b>Нормализация (Min-Max Scaling):</b><br>   - <b>Формула:</b> $x'_{norm} = \\frac{x - x_{min}}{x_{max} - x_{min}}$<br>   - <b>Назначение:</b> Гарантированно приводит все значения к диапазону [0, 1]. Полезна, когда мы точно знаем, что данные должны быть в определенных границах, и нет сильных выбросов.<br>2. <b>Стандартизация (Z-score Standardization):</b><br>   - <b>Формула:</b> $x'_{std} = \\frac{x - \\mu}{\\sigma}$<br>   - <b>Назначение:</b> Преобразует данные так, чтобы они имели среднее 0 и стандартное отклонение 1. Не имеет жестких границ, поэтому более устойчива к выбросам. Является наиболее распространенным и рекомендуемым методом решкалирования в большинстве случаев.</p><p><b>Применение на практике:</b> Это обязательный шаг предобработки для многих моделей. В "sklearn.preprocessing" есть классы <code>MinMaxScaler</code> и <code>StandardScaler". Их важно обучать (<code>.fit()"") только на обучающих данных, а затем применять (<code>.transform()</code>) и к обучающим, и к тестовым данным, чтобы избежать утечки информации.</p>`,
          // Q40
          `<h3>Суть</h3><p>Категориальные признаки (например, "город", "цвет") нужно преобразовать в числа, чтобы модели могли с ними работать. Основные методы — целочисленное и one-hot кодирование.</p><h3>Подробное описание</h3><p>Модели машинного обучения понимают только числа. Поэтому текстовые категории нужно закодировать.<br><b>Основные методы:</b><br>1. <b>Целочисленное кодирование (Label/Ordinal Encoding):</b> Каждой уникальной категории присваивается целое число (0, 1, 2, ...).<br>   - <b>Проблема:</b> Модель может ошибочно интерпретировать эти числа как имеющие порядок (например, что "Москва" (2) "больше", чем "Лондон" (1)).<br>   - <b>Когда использовать:</b> Только для <b>порядковых (ordinal)</b> признаков, где порядок действительно существует (например, 'S' -> 0, 'M' -> 1, 'L' -> 2).<br>2. <b>One-Hot Encoding (OHE, фиктивные переменные):</b><br>   - <b>Как работает:</b> Для признака с $N$ категориями создается $N$ новых бинарных (0/1) признаков. Для каждого объекта только один из этих новых признаков будет равен 1 (тот, что соответствует его категории), а остальные — 0.<br>   - <b>Пример:</b> Признак "Цвет" с категориями ['Красный', 'Синий'] превратится в два новых признака: "Цвет_Красный" и "Цвет_Синий".<br>   - <b>Плюсы:</b> Не вносит ложного порядка. Это стандартный и самый безопасный метод для <b>номинальных</b> признаков.<br>   - <b>Минусы:</b> Сильно увеличивает количество признаков, если категорий очень много.</p><p><b>Применение на практике:</b> Для порядковых признаков используется <code>sklearn.preprocessing.OrdinalEncoder</code>. Для номинальных — <code>sklearn.preprocessing.OneHotEncoder</code> или функция <code>pandas.get_dummies()"".</p>`,
          // Q41
          `<h3>Суть</h3><p>Визуализация в ML используется не только для анализа данных (EDA), но и для оценки и интерпретации моделей: построения кривых обучения, отображения важности признаков или границ принятия решений.</p><h3>Подробное описание</h3><p>Помимо EDA, визуализация играет важную роль на всех этапах ML-проекта:<br>1. <b>Предварительный анализ (EDA):</b> Гистограммы, диаграммы рассеяния, box-plot'ы, тепловые карты для понимания данных (см. вопрос 37).<br>2. <b>Диагностика модели:</b><br>   - <b>Кривые обучения и валидации:</b> Помогают диагностировать недо/переобучение (см. вопрос 43).<br>   - <b>Матрица ошибок (Confusion Matrix):</b> Визуализация в виде тепловой карты помогает быстро понять, какие классы модель путает между собой.<br>   - <b>ROC-кривая:</b> Показывает компромисс между True Positive Rate и False Positive Rate, используется для оценки качества бинарных классификаторов.<br>3. <b>Интерпретация модели:</b><br>   - <b>Важность признаков (Feature Importance):</b> Столбчатые диаграммы, показывающие, какие признаки внесли наибольший вклад в предсказания модели (особенно актуально для древовидных моделей).<br>   - <b>Визуализация границ принятия решений:</b> Для моделей с 2 признаками можно нарисовать, как модель делит пространство на классы.<br>   - <b>Визуализация структуры дерева:</b> Для <code>DecisionTree" можно нарисовать все дерево целиком.<br>4. <b>Понижение размерности:</b> Методы вроде PCA и t-SNE используются для визуализации многомерных данных на 2D-плоскости.</p><p><b>Применение на практике:</b> Основные инструменты — <b>Matplotlib</b> и <b>Seaborn</b>. Для интерактивных графиков используют <b>Plotly</b>. Библиотеки "sklearn" и "scikit-plot" также предоставляют готовые функции для построения диагностических графиков.</p>`,
          // Q42
          `<h3>Суть</h3><p>Чтобы выбрать лучшую модель, ее эффективность нужно оценивать на данных, которые не использовались для обучения. Для этого данные делят на обучающий и валидационный (или тестовый) наборы.</p><h3>Подробное описание</h3><p>Оценивать модель на тех же данных, на которых она обучалась — бессмысленно. Переобученная модель покажет на них 100% качество, но будет бесполезна в реальности. Поэтому данные необходимо делить.<br><b>Схемы разделения:</b><br>1. <b>Простое разделение (Train-Test Split):</b> Данные делятся на две части: <b>обучающий набор (train set)</b>, на котором подбираются параметры модели, и <b>тестовый набор (test set)</b>, на котором модель оценивается один раз в самом конце, чтобы получить финальную, непредвзятую оценку.<br>2. <b>Разделение на три части (Train-Validation-Test Split):</b> Более правильная схема, когда нужно подбирать гиперпараметры.<br>   - <b>Обучающий набор (train set):</b> Для обучения модели с конкретным набором гиперпараметров.<br>   - <b>Валидационный набор (validation set):</b> Для оценки и сравнения моделей с <b>разными</b> гиперпараметрами. По результатам на этом наборе мы выбираем лучшую модель.<br>   - <b>Тестовый набор (test set):</b> "Неприкасаемый" набор. Используется один раз для финальной оценки самой лучшей модели, выбранной на валидационном наборе.<br><b>Кросс-валидация</b> (см. вопрос 35) является более надежной альтернативой простому валидационному набору, так как она использует все данные и для обучения, и для валидации, давая более стабильную оценку.</p>`,
          // Q43
          `<h3>Суть</h3><p>Кривые обучения — это графики, показывающие производительность модели на обучающем и валидационном наборах в зависимости от количества обучающих данных. Они помогают диагностировать недообучение и переобучение.</p><h3>Подробное описание</h3><p>Анализ кривых обучения — мощный инструмент диагностики. На графике строятся две линии: ошибка на обучающей выборке и ошибка на валидационной выборке.<br><b>1. Случай недообучения (High Bias):</b><br>   - Обе кривые (обучающая и валидационная) сходятся к высокому значению ошибки.<br>   - <b>Диагноз:</b> Модель слишком проста. Добавление новых данных не поможет.<br>   - <b>Лечение:</b> Усложнить модель (например, использовать полиномиальные признаки, более глубокое дерево).<br><b>2. Случай переобучения (High Variance):</b><br>   - Существует большой разрыв между кривыми: ошибка на обучении очень низкая, а на валидации — значительно выше.<br>   - <b>Диагноз:</b> Модель слишком сложная, она выучила шум.<br>   - <b>Лечение:</b> Собрать больше данных (кривые будут сходиться), применить регуляризацию, упростить модель.<br><b>3. "Золотая середина":</b><br>   - Обе кривые сходятся к низкому значению ошибки, и разрыв между ними небольшой.<br>   - <b>Диагноз:</b> Модель хорошо сбалансирована.</p><p><b>Применение на практике:</b> В <code>sklearn.model_selection" есть функция <code>learning_curve</code> для построения таких графиков.</p>`,
          // Q44
          `<h3>Суть</h3><p>Регуляризация — это метод борьбы с переобучением путем добавления "штрафа" за сложность модели в ее функцию потерь. Это заставляет модель использовать меньшие веса, делая ее проще и стабильнее.</p><h3>Подробное описание</h3><p><b>Назначение:</b> Основная цель регуляризации — предотвратить переобучение (уменьшить variance модели). Это достигается путем ограничения величины весов (параметров) модели.<br><b>Формализация:</b> К обычной функции потерь $J(\\theta)$ добавляется регуляризационный член, взвешенный с коэффициентом регуляризации $\\lambda$ (или "alpha" в sklearn):<br>$$ J_{reg}(\\theta) = J(\\theta) + \\lambda R(\\theta) $$Чем больше $\\lambda$, тем сильнее штраф за большие веса, и тем проще будет итоговая модель.<br><b>Основные виды:</b><br>1. <b>L2-регуляризация (Ridge, гребневая регрессия):</b><br>   - Штраф пропорционален сумме квадратов весов: $R(\\theta) = \\sum_{j=1}^{n} \\theta_j^2$.<br>   - Она делает веса очень маленькими, но не обнуляет их полностью. <br>2. <b>L1-регуляризация (Lasso):</b><br>   - Штраф пропорционален сумме модулей весов: $R(\\theta) = \\sum_{j=1}^{n} |\\theta_j|$.<br>   - Может обнулять веса некоторых признаков, тем самым производя <b>отбор признаков</b>. Это полезно, когда мы подозреваем, что многие признаки нерелевантны.<br>3. <b>Elastic Net:</b> Комбинация L1 и L2 регуляризации.</p><p><b>Применение на практике:</b> В моделях <code>Ridge</code>, <code>Lasso</code>, <code>ElasticNet", а также в <code>LogisticRegression</code> (параметр <code>penalty='l1'</code> или <code>'l2'</code>) и <code>SVC</code> (параметр <code>C" обратно пропорционален силе регуляризации).</p>`,
          // Q45
          `<h3>Суть</h3><p>Получить хорошие данные — это сложная задача. Данные часто находятся в разных системах, имеют разный формат, и их нужно собрать, очистить и правильно объединить, прежде чем использовать для обучения.</p><h3>Подробное описание</h3><p><b>Сбор данных (Data Collection):</b><br>Данные для ML могут поступать из множества источников:<br> - Базы данных (SQL, NoSQL).<br> - API внешних сервисов.<br> - Веб-скрапинг (сбор данных с веб-сайтов).<br> - Лог-файлы серверов и приложений.<br> - Файлы (CSV, JSON, Excel).<br>Важно обеспечить надежность и воспроизводимость процесса сбора.<br><b>Интеграция данных (Data Integration):</b><br>Это процесс объединения данных из разных источников. Основные проблемы:<br> - <b>Разные схемы:</b> Несовпадение названий колонок, форматов данных (например, дата в одном источнике 'dd.mm.yyyy', в другом 'yyyy-mm-dd').<br> - <b>Консистентность:</b> Одно и то же понятие может быть названо по-разному (e.g., "США", "USA", "Соединенные Штаты").<br> - <b>Сопоставление записей:</b> Сложность в определении, что запись о клиенте "Иван Иванов" из одной таблицы и "Ivanov I." из другой — это один и тот же человек.<br>Эти задачи часто решаются в рамках процессов <b>ETL (Extract, Transform, Load)</b>, где данные извлекаются, преобразуются к единому формату и загружаются в хранилище данных (Data Warehouse) для дальнейшего анализа.</p>`,
          // Q46
          `<h3>Суть</h3><p>Чистые данные — это данные, которые являются точными, полными, непротиворечивыми и правильно структурированными, что делает их пригодными для надежного моделирования.</p><h3>Подробное описание</h3><p>Качество данных напрямую определяет качество модели. Основные требования к данным:<br>1. <b>Точность (Accuracy):</b> Данные должны соответствовать действительности. Например, возраст клиента не может быть отрицательным.<br>2. <b>Полнота (Completeness):</b> В данных должно быть как можно меньше пропусков. Если пропусков много, ценность признака падает.<br>3. <b>Непротиворечивость (Consistency):</b> Внутри набора данных не должно быть логических противоречий. Например, дата увольнения не может быть раньше даты приема на работу. Одно и то же значение должно быть записано одинаково ("Москва", а не "МСК", "г. Москва").<br>4. <b>Актуальность (Timeliness):</b> Данные должны быть свежими и релевантными текущему моменту, особенно для задач, где зависимости меняются со временем (например, прогнозирование спроса).<br>5. <b>Структурированность ("Tidiness"):</b> Данные должны быть организованы в формате "одна строка — одно наблюдение, один столбец — один признак".</p>`,
          // Q47
          `<h3>Суть</h3><p>Основные задачи описательного анализа — это обобщение и суммирование ключевых характеристик набора данных с помощью основных статистик и методов визуализации, чтобы понять его природу.</p><h3>Подробное описание</h3><p>Описательный (дескриптивный) анализ отвечает на вопрос "Что произошло?". Он не делает выводов о причинах, а лишь описывает данные. Основные задачи:<br>1. <b>Измерение центральной тенденции:</b> Определение "типичного" значения для признака.<br>   - <b>Среднее (Mean):</b> Сумма всех значений, деленная на их количество. Чувствительно к выбросам.<br>   - <b>Медиана (Median):</b> Средний элемент в отсортированном ряду. Устойчива к выбросам.<br>   - <b>Мода (Mode):</b> Самое часто встречающееся значение.<br>2. <b>Измерение изменчивости (разброса):</b> Насколько сильно данные варьируются вокруг центрального значения.<br>   - <b>Стандартное отклонение (Standard Deviation) и Дисперсия (Variance):</b> Показывают среднее отклонение от среднего.<br>   - <b>Размах (Range):</b> Разница между максимумом и минимумом.<br>   - <b>Квартили (Quartiles):</b> Значения, которые делят данные на четыре равные части.<br>3. <b>Анализ формы распределения:</b> Визуальная и численная оценка распределения данных.<br>   - <b>Гистограммы и графики плотности:</b> Показывают форму распределения.<br>   - <b>Асимметрия (Skewness) и Эксцесс (Kurtosis):</b> Числовые меры "скошенности" и "остроты пика" распределения.</p><p><b>Применение на практике:</b> Метод <code>.describe()</code> в "pandas" сразу вычисляет большинство этих статистик для всех числовых столбцов.</p>`,
          // Q48
          `<h3>Суть</h3><p>Полиномиальные модели позволяют улавливать нелинейные зависимости в данных путем добавления в модель степенных признаков (например, $x^2, x^3$) и их взаимодействий, после чего к ним применяется обычная линейная модель.</p><h3>Подробное описание</h3><p>Если зависимость между признаками и целью нелинейная, простая линейная регрессия ($h(x) = \\theta_0 + \\theta_1 x_1$) будет работать плохо. <b>Полиномиальная регрессия</b> решает эту проблему. Идея в том, чтобы искусственно создать новые признаки, являющиеся степенями или произведениями исходных.<br>Например, для одного признака $x$ модель может стать:<br>$$ h(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 $$А для двух признаков $x_1, x_2$ можно создать модель вида:<br>$$ h(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_1^2 + \\theta_4 x_2^2 + \\theta_5 x_1 x_2 $$Такая модель все еще является <b>линейной по параметрам $\\theta$</b>, поэтому для ее обучения можно использовать те же методы, что и для линейной регрессии (например, градиентный спуск).<br><b>Преимущества:</b> Позволяет моделировать сложные нелинейные зависимости.<br><b>Недостатки:</b> Очень легко <b>переобучиться</b>, особенно при высокой степени полинома. Количество признаков может резко возрасти. Требует обязательной регуляризации.</p><p><b>Применение на практике:</b> В "sklearn" для генерации таких признаков используется <code>preprocessing.PolynomialFeatures</code> в связке с линейной моделью (<code>LinearRegression</code>, <code>Ridge</code>) внутри <code>Pipeline</code>.</p>`,
          // Q49
          `<h3>Суть</h3><p>Подготовка данных к обучению включает три основных вида преобразований: работа с пропусками (заполнение), кодирование категориальных признаков в числа и решкалирование (нормализация/стандартизация) числовых признаков.</p><h3>Подробное описание</h3><p>Это краткое изложение ключевых шагов предобработки данных:<br>1. <b>Обработка пропущенных значений:</b><br>   - <b>Удаление:</b> Удаление строк или столбцов с пропусками (риск потери данных).<br>   - <b>Импутация (заполнение):</b> Замена пропусков константой, средним, медианой, модой или предсказаниями другой модели (<code>SimpleImputer</code>, <code>KNNImputer</code>).<br>2. <b>Преобразование категориальных признаков:</b><br>   - <b>Label/Ordinal Encoding:</b> Для порядковых признаков, где важен порядок (<code>OrdinalEncoder</code>).<br>   - <b>One-Hot Encoding:</b> Для номинальных признаков, где порядка нет. Создает новые бинарные столбцы (<code>OneHotEncoder</code>, <code>pd.get_dummies</code>).<br>3. <b>Решкалирование числовых признаков:</b><br>   - <b>Стандартизация (Standardization):</b> Приведение к среднему 0 и стд. отклонению 1. Наиболее частый выбор (<code>StandardScaler</code>).<br>   - <b>Нормализация (Normalization):</b> Приведение к диапазону [0, 1] (<code>MinMaxScaler</code>).<br>4. <b>Инженерия признаков (Feature Engineering):</b><br>   - Создание новых признаков из существующих (например, полиномиальных) или извлечение информации (например, из дат).<br><br><b>Применение на практике:</b> <code>ColumnTransformer</code> из <code>sklearn.compose</code> позволяет применять разные преобразования к разным колонкам датасета в рамках единого конвейера (<code>Pipeline</code>).</p>`,
          // Q50
          `<h3>Суть</h3><p>Выбор признаков (Feature Selection) — это процесс отбора наиболее значимого подмножества признаков из исходного набора для построения модели. Это помогает уменьшить переобучение, ускорить обучение и улучшить интерпретируемость.</p><h3>Подробное описание</h3><p>Наличие лишних, нерелевантных или избыточных признаков может ухудшить качество модели. Процесс их отбора делится на три основные группы методов:<br>1. <b>Методы-фильтры (Filter Methods):</b><br>   - Признаки оцениваются и ранжируются независимо от модели на основе их статистических свойств (например, корреляции с целевой переменной, взаимной информации).<br>   - <b>Плюсы:</b> Быстро.<br>   - <b>Минусы:</b> Не учитывают взаимодействие признаков и специфику модели.<br>   - <b>Пример:</b> <code>SelectKBest</code> в "sklearn".<br>2. <b>Методы-обертки (Wrapper Methods):</b><br>   - Используют модель как "черный ящик" для оценки качества различных подмножеств признаков. Итеративно добавляют или удаляют признаки, оценивая результат на модели.<br>   - <b>Плюсы:</b> Учитывают модель, часто дают лучший результат.<br>   - <b>Минусы:</b> Очень медленные и вычислительно дорогие.<br>   - <b>Пример:</b> Рекурсивное исключение признаков (<code>RFE</code>).<br>3. <b>Встроенные методы (Embedded Methods):</b><br>   - Отбор признаков происходит непосредственно в процессе обучения модели. Это наиболее предпочтительный подход.<br>   - <b>Примеры:</b> L1-регуляризация (Lasso), которая обнуляет веса неважных признаков; важность признаков (<code>feature_importances_"), получаемая из древовидных моделей (Random Forest, Gradient Boosting).</p>`,
          // Q51
          `<h3>Суть</h3><p>Обучение без учителя — это класс задач ML, где алгоритм ищет скрытые закономерности и структуру в неразмеченных данных, то есть без "правильных ответов".</p><h3>Подробное описание</h3><p><b>Общая характеристика:</b> В отличие от обучения с учителем, где есть пары (признаки $X$, метка $y$), в обучении без учителя есть только признаки $X$. Цель — не предсказать метку, а понять внутреннюю структуру самих данных.<br><b>Особенности:</b><br> - <b>Нет правильных ответов:</b> Оценка качества моделей сложнее, так как нет эталонных меток для сравнения. Часто используются внутренние метрики (например, Silhouette Score для кластеризации) или экспертная оценка.<br> - <b>Исследовательский характер:</b> Часто используется для предварительного анализа данных, чтобы лучше понять их природу перед решением основной задачи.<br><b>Примеры задач:</b><br> - <b>Кластеризация (Clustering):</b> Группировка похожих объектов. <i>Пример:</i> сегментация клиентов по поведению.<br> - <b>Понижение размерности (Dimensionality Reduction):</b> Уменьшение количества признаков. <i>Пример:</i> визуализация многомерных данных на 2D-графике.<br> - <b>Поиск аномалий (Anomaly Detection):</b> Выявление нетипичных объектов. <i>Пример:</i> обнаружение мошеннических транзакций.<br> - <b>Поиск ассоциативных правил:</b> Нахождение закономерностей вида "если купили товар А, то часто покупают и товар Б".</p>`,
          // Q52
          `<h3>Суть</h3><p>Кластеризация — это задача обучения без учителя по разделению множества объектов на группы (кластеры) так, чтобы объекты внутри одного кластера были максимально похожи друг на друга, а объекты из разных кластеров — максимально различны.</p><h3>Подробное описание</h3><p><b>Формализация:</b> Имеется набор данных $X$. Задача — разбить его на $K$ непересекающихся подмножеств $C_1, C_2, ..., C_K$, называемых кластерами. Цель — минимизировать внутрикластерное расстояние и максимизировать межкластерное расстояние.<br><b>Применение:</b><br> - <b>Маркетинг:</b> Сегментация клиентов для целевых кампаний.<br> - <b>Биология:</b> Классификация генов по паттернам экспрессии.<br> - <b>Обработка изображений:</b> Сегментация изображения на области (например, небо, земля, вода).<br> - <b>Обработка текстов:</b> Группировка новостных статей по темам.<br><b>Метрики качества кластеризации:</b><br> - <b>Внутренние (когда нет истинных меток):</b><br>   - <b>Silhouette Score (Коэффициент силуэта):</b> Показывает, насколько объект похож на свой кластер по сравнению с другими. Значения от -1 до 1. Чем ближе к 1, тем лучше.<br>   - <b>Davies-Bouldin Index:</b> Оценивает среднее "сходство" между каждым кластером и его наиболее похожим кластером. Чем меньше значение, тем лучше.<br> - <b>Внешние (когда истинные метки известны, для оценки):</b><br>   - <b>Adjusted Rand Index (ARI):</b> Измеряет сходство между истинным и предсказанным разбиениями. 1 — идеальное совпадение.</p>`,
          // Q53
          `<h3>Суть</h3><p>K-Means — это популярный алгоритм кластеризации, который делит данные на заранее заданное число кластеров (K) путем итеративного присвоения точек к ближайшему центру кластера (центроиду) и пересчета этих центров.</p><h3>Подробное описание</h3><p><b>Алгоритм работы:</b><br>1. <b>Инициализация:</b> Выбрать количество кластеров $K$. Случайным образом разместить $K$ точек-центроидов в пространстве признаков.<br>2. <b>Повторять до сходимости:</b><br>   a. <b>Шаг присвоения (Assignment step):</b> Для каждой точки данных найти ближайший к ней центроид (обычно по евклидову расстоянию) и отнести эту точку к его кластеру.<br>   b. <b>Шаг обновления (Update step):</b> Для каждого кластера пересчитать положение его центроида как среднее арифметическое (центр масс) всех точек, попавших в этот кластер.<br>3. <b>Остановка:</b> Алгоритм останавливается, когда на шаге присвоения ни одна точка не меняет свой кластер.<br><b>Особенности:</b><br> - <b>Необходимо задавать K:</b> Для выбора оптимального K часто используют "метод локтя" (Elbow method).<br> - <b>Чувствительность к инициализации:</b> Результат может зависеть от начального положения центроидов. Для решения проблемы алгоритм запускают несколько раз с разными стартами (<code>n_init</code> в "sklearn").<br> - <b>Предположения:</b> Алгоритм неявно предполагает, что кластеры имеют сферическую форму и примерно одинаковый размер.</p><p><b>Применение на практике:</b> <code>sklearn.cluster.KMeans".</p>`,
          // Q54
          `<h3>Суть</h3><p>Иерархическая кластеризация строит "дерево" вложенных друг в друга кластеров. Начиная с отдельных точек, она последовательно объединяет самые близкие кластеры, пока все не окажутся в одном.</p><h3>Подробное описание</h3><p><b>Агломеративная иерархическая кластеризация</b> работает "снизу-вверх".<br><b>Алгоритм:</b><br>1. <b>Начало:</b> Каждый объект данных считается отдельным кластером.<br>2. <b>Итерации:</b> На каждом шаге находятся два самых близких кластера и объединяются в один.<br>3. <b>Конец:</b> Процесс повторяется до тех пор, пока все объекты не будут объединены в один большой кластер.<br>Результатом работы является <b>дендрограмма</b> — древовидная диаграмма, которая наглядно показывает последовательность объединений. "Разрезая" дендрограмму на определенной высоте, можно получить нужное количество кластеров.<br><b>Способы определения расстояния между кластерами (linkage):</b><br> - <b>Single:</b> по расстоянию между ближайшими точками.<br> - <b>Complete:</b> по расстоянию между самыми дальними точками.<br> - <b>Average:</b> по среднему расстоянию между всеми парами точек.<br> - <b>Ward:</b> минимизирует дисперсию при объединении кластеров (часто лучший выбор).<br><b>Плюсы:</b> Не требует заранее задавать число кластеров. Дендрограмма дает богатую информацию о структуре данных.<br><b>Минусы:</b> Вычислительно сложен (O(N²)), плохо масштабируется на большие датасеты.</p><p><b>Применение на практике:</b> <code>sklearn.cluster.AgglomerativeClustering".</p>`,
          // Q55
          `<h3>Суть</h3><p>DBSCAN — это плотностной алгоритм, который находит кластеры как области с высокой плотностью точек, разделенные областями с низкой плотностью. Он умеет находить кластеры произвольной формы и определять шумовые точки (выбросы).</p><h3>Подробное описание</h3><p><b>DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</b> не требует заранее знать число кластеров. Его работа основана на двух параметрах:<br> - <b><code>eps</code> (ε):</b> Радиус окрестности. Максимальное расстояние между двумя точками, чтобы они считались соседями.<br> - <b><code>min_samples</code>:</b> Минимальное число точек в "eps"-окрестности, чтобы точка считалась <b>основной (core point)</b>.<br><b>Алгоритм классифицирует точки на три типа:</b><br>1. <b>Основная точка (Core point):</b> Точка, у которой в "eps"-окрестности находится не менее <code>min_samples</code> соседей.<br>2. <b>Граничная точка (Border point):</b> Точка, которая не является основной, но находится в "eps"-окрестности какой-либо основной точки.<br>3. <b>Шум (Noise):</b> Точка, которая не является ни основной, ни граничной.<br><b>Кластер в DBSCAN</b> — это множество всех основных точек, достижимых друг от друга, плюс все их граничные точки. Алгоритм находит такие плотные области и объединяет их в кластеры.<br><b>Плюсы:</b> Способен находить кластеры сложной формы, устойчив к шуму, не требует задавать K.<br><b>Минусы:</b> Чувствителен к параметрам <code>eps</code> и <code>min_samples</code>, плохо работает с кластерами сильно различающейся плотности.</p><p><b>Применение на практике:</b> <code>sklearn.cluster.DBSCAN".</p>`,
          // Q56
          `<h3>Суть</h3><p>Понижение размерности — это процесс сокращения количества признаков в данных. Метод главных компонент (PCA) делает это, находя новые оси (компоненты), вдоль которых данные имеют наибольший разброс, и отбрасывая наименее важные.</p><h3>Подробное описание</h3><p><b>Задача понижения размерности (Dimensionality Reduction)</b> решает несколько проблем:<br> - <b>Проклятие размерности:</b> В многомерных пространствах данные становятся разреженными, что ухудшает работу многих алгоритмов.<br> - <b>Визуализация:</b> Человек не может воспринимать данные более чем в 3 измерениях.<br> - <b>Вычислительная сложность:</b> Меньше признаков — быстрее обучение.<br> - <b>Шум:</b> Удаление менее значимых измерений может убрать шум из данных.<br><b>Метод главных компонент (Principal Component Analysis, PCA):</b><br>Это самый популярный линейный метод понижения размерности. PCA находит новое ортогональное координатное пространство, в котором оси (называемые <b>главными компонентами</b>) направлены вдоль максимальной дисперсии данных.<br> - Первая главная компонента — это направление, объясняющее наибольшую долю дисперсии.<br> - Вторая — ортогональна первой и объясняет максимальную из оставшейся дисперсии, и т.д.<br>Для понижения размерности мы просто отбрасываем последние компоненты, которые несут меньше всего информации (дисперсии), и проецируем данные на оставшиеся.<br><b>Важно:</b> Перед применением PCA данные необходимо <b>стандартизировать</b> (<code>StandardScaler</code>).</p><p><b>Применение на практике:</b> <code>sklearn.decomposition.PCA".</p>`,
          // Q57
          `<h3>Суть</h3><p>t-SNE — это мощный, но сложный алгоритм понижения размерности, который используется почти исключительно для визуализации многомерных данных (например, в 2D). Он отлично показывает кластерную структуру, но не предназначен для предобработки.</p><h3>Подробное описание</h3><p><b>t-SNE (t-distributed Stochastic Neighbor Embedding)</b> — это нелинейный метод, который особенно хорош для выявления локальной структуры в данных.<br><b>Общая характеристика:</b> Алгоритм пытается сохранить "соседские" отношения между точками. Он моделирует сходство между точками в исходном пространстве как условную вероятность и пытается найти такое представление в малом (2D или 3D) пространстве, где эта вероятностная модель сходства будет наилучшим образом сохранена.<br><b>Применение:</b> Основное и практически единственное применение — <b>визуализация</b> для исследовательского анализа данных. Он помогает "увидеть" кластеры, которые могут существовать в данных.<br><b>Особенности и предостережения:</b><br> - <b>Не для предобработки:</b> Не следует использовать t-SNE как шаг предобработки перед классификатором, так как он не сохраняет глобальную структуру и плотность.<br> - <b>Интерпретация:</b> Размеры кластеров и расстояния между ними на t-SNE графике не имеют прямого физического смысла! Большое расстояние между двумя кластерами на графике не обязательно означает, что они "далеко" друг от друга в исходном пространстве. Главное, что он показывает — это само наличие отдельных групп.<br> - <b>Параметры:</b> Результат сильно зависит от гиперпараметра <code>perplexity</code> (условное "число соседей").</p><p><b>Применение на практике:</b> <code>sklearn.manifold.TSNE".</p>`,
          // Q58
          `<h3>Суть</h3><p>Обнаружение аномалий — это задача поиска объектов, которые сильно отличаются от "нормального" большинства. Один из методов основан на предположении, что нормальные данные подчиняются гауссову (нормальному) распределению, а аномалии — нет.</p><h3>Подробное описание</h3><p>Задача также известна как <b>поиск выбросов (outlier detection)</b>. Она актуальна для выявления мошенничества, сбоев оборудования, редких событий.<br><b>Метод на основе многомерного гауссова распределения:</b><br>1. <b>Предположение:</b> Мы считаем, что признаки "нормальных" объектов $x$ распределены согласно многомерному нормальному (гауссову) распределению.<br>2. <b>Обучение:</b> На обучающем наборе, состоящем из нормальных примеров, мы оцениваем параметры этого распределения: вектор средних $\\mu$ и ковариационную матрицу $\\Sigma$.<br>3. <b>Предсказание:</b> Для нового объекта $x_{test}$ мы вычисляем значение функции плотности вероятности $p(x_{test})$ для нашего оцененного распределения.<br>4. <b>Решение:</b> Если $p(x_{test}) < \\epsilon$ (где $\\epsilon$ — некоторый порог), то объект считается аномалией, так как он имеет очень низкую вероятность появления в "нормальном" распределении.<br><b>Плюсы:</b> Этот метод способен улавливать сложные взаимосвязи между признаками (благодаря ковариационной матрице). Например, он может найти аномалию, где каждый признак по отдельности в норме, но их комбинация — нет.<br><b>Минусы:</b> Требует, чтобы данные действительно были распределены по Гауссу, и чувствителен к наличию аномалий в обучающей выборке.</p>`,
          // Q59
          `<h3>Суть</h3><p>Алгоритм кластеризации DBSCAN можно использовать для обнаружения аномалий, так как он по своей природе выделяет точки, не принадлежащие ни к одному плотному кластеру, в отдельную категорию "шум", которая и является аномалиями.</p><h3>Подробное описание</h3><p>В отличие от методов, делающих предположения о распределении данных, DBSCAN является непараметрическим подходом к поиску аномалий.<br><b>Как это работает:</b><br>Принцип работы DBSCAN (см. вопрос 55) заключается в поиске плотных областей. В процессе работы он классифицирует все точки на три типа: основные, граничные и шумовые.<br> - <b>Основные и граничные точки</b> формируют кластеры "нормальных" данных.<br> - <b>Шумовые точки (Noise)</b> — это те точки, которые не попали ни в один кластер. Они лежат в разреженных областях пространства.<br>Именно эти шумовые точки и интерпретируются как <b>аномалии</b> или <b>выбросы</b>.<br><b>Преимущества:</b><br> - Не требует предположений о форме распределения данных.<br> - Способен находить аномалии в данных со сложной структурой.<br> - Одновременно решает задачу кластеризации и поиска аномалий.<br><b>Недостатки:</b><br> - Результат сильно зависит от выбора гиперпараметров <code>eps</code> и <code>min_samples</code>.<br> - Плохо справляется с данными, где "нормальные" кластеры имеют сильно различающуюся плотность, так как параметры <code>eps</code> и <code>min_samples</code> глобальны для всего набора данных.</p>`,
          // Q60
          `<h3>Суть</h3><p>Ансамбли — это методы, которые объединяют предсказания нескольких отдельных моделей (базовых) для получения одного, но более качественного и стабильного итогового предсказания.</p><h3>Подробное описание</h3><p>Принцип "мудрости толпы": коллективное решение группы экспертов часто лучше, чем решение одного, даже самого лучшего, эксперта. В машинном обучении это работает так же.<br><b>Цель ансамблирования:</b><br> - <b>Повышение точности:</b> Комбинируя модели, можно скомпенсировать ошибки каждой из них.<br> - <b>Повышение стабильности (робастности):</b> Итоговое решение становится менее чувствительным к шуму и особенностям обучающей выборки.<br><b>Условия эффективности:</b><br>1. <b>Точность базовых моделей:</b> Каждая модель в ансамбле должна быть лучше случайного угадывания.<br>2. <b>Разнообразие базовых моделей (Diversity):</b> Модели должны ошибаться на разных объектах. Если все модели одинаковы, ансамбль не даст выигрыша. Разнообразие достигается за счет обучения моделей на разных подвыборках данных, на разных наборах признаков или использования разных алгоритмов.<br><b>Основные типы ансамблей:</b><br> - <b>Бэггинг (Bagging):</b> Модели обучаются параллельно и независимо на случайных подвыборках данных. (Пример: Случайный лес).<br> - <b>Бустинг (Boosting):</b> Модели обучаются последовательно, каждая следующая исправляет ошибки предыдущей. (Пример: Градиентный бустинг).<br> - <b>Стекинг (Stacking):</b> Предсказания базовых моделей используются как признаки для обучения "мета-модели".</p>`,
          // Q61
          `<h3>Суть</h3><p>Случайный лес — это ансамбль, состоящий из множества решающих деревьев. Каждое дерево обучается на своей случайной подвыборке данных и признаков, а итоговое решение принимается "голосованием" всех деревьев.</p><h3>Подробное описание</h3><p><b>Случайный лес (Random Forest)</b> — это усовершенствованная версия бэггинга, специально для решающих деревьев.<br><b>Алгоритм построения:</b><br>1. Из исходной обучающей выборки создается множество ($N_{trees}$) случайных подвыборок с возвращением (метод <b>бутстрап</b>). Размер каждой подвыборки равен исходной.<br>2. На каждой подвыборке обучается одно решающее дерево. При этом в процессе роста дерева, при каждом разбиении узла, выбирается не лучший признак из всех, а лучший из <b>случайного подмножества</b> признаков.<br>3. В итоге получается ансамбль из $N_{trees}$ разных деревьев.<br><b>Процесс предсказания:</b><br> - <b>Для классификации:</b> Каждый объект пропускается через все деревья. Итоговым ответом является класс, за который "проголосовало" большинство деревьев.<br> - <b>Для регрессии:</b> Итоговый ответ — среднее арифметическое предсказаний всех деревьев.<br><b>Эффект:</b> Случайный лес борется с главным недостатком решающих деревьев — склонностью к переобучению. За счет усреднения множества разнообразных (благодаря бутстрапу и случайности признаков) деревьев, итоговая модель имеет значительно меньший разброс (variance) и является более стабильной.</p><p><b>Применение на практике:</b> <code>sklearn.ensemble.RandomForestClassifier</code> и <code>RandomForestRegressor</code>.</p>`,
          // Q62
          `<h3>Суть</h3><p>Стекинг — это сложный метод ансамблирования, при котором предсказания нескольких разных моделей ("базовых") используются как новые признаки для обучения финальной "мета-модели", которая и выносит итоговое решение.</p><h3>Подробное описание</h3><p>Стекинг (или смешивание) пытается научиться оптимально комбинировать предсказания от нескольких моделей.<br><b>Архитектура:</b><br> - <b>Уровень 0 (Base Models):</b> На этом уровне находятся несколько разных базовых моделей (например, <code>LogisticRegression</code>, <code>KNeighborsClassifier</code>, <code>RandomForestClassifier"). Они обучаются на исходных данных.<br> - <b>Уровень 1 (Meta-Model):</b> Здесь находится одна мета-модель (например, <code>Ridge</code> или <code>XGBoost"). Она обучается не на исходных признаках, а на предсказаниях, которые сгенерировали модели с Уровня 0.<br><b>Процесс обучения (для предотвращения утечки данных):</b><br>1. Обучающая выборка делится на несколько частей (фолдов), как в кросс-валидации.<br>2. Модели Уровня 0 поочередно обучаются на $K-1$ фолдах и делают предсказания для оставшегося $K$-го фолда. Эти предсказания ("out-of-fold predictions") собираются.<br>3. После того как для каждого объекта в обучающей выборке получены предсказания от базовых моделей, этот новый набор данных (где признаки — это предсказания) используется для обучения мета-модели.<br><b>Особенность:</b> Стекинг позволяет находить сложные зависимости в предсказаниях базовых моделей и часто дает небольшой, но стабильный прирост в качестве по сравнению с другими методами.</p><p><b>Применение на практике:</b> <code>sklearn.ensemble.StackingClassifier</code> и <code>StackingRegressor</code>.</p>`,
          // Q63
          `<h3>Суть</h3><p>Бэггинг (Bagging) — это метод ансамблирования, при котором множество экземпляров одной и той же модели обучаются параллельно на разных случайных подвыборках данных, а их предсказания усредняются. Основная цель — уменьшить разброс (variance) модели.</p><h3>Подробное описание</h3><p><b>Бэггинг (Bagging)</b> расшифровывается как <b>B</b>ootstrap <b>Agg</b>regat<b>ing</b>.<br><b>Алгоритм:</b><br>1. <b>Bootstrap (бутстрап):</b> Из исходной обучающей выборки размером $N$ создается $M$ новых выборок такого же размера $N$ путем случайного выбора с возвращением. Каждая такая выборка содержит примерно 63% уникальных объектов из исходной.<br>2. <b>Training:</b> На каждой из $M$ бутстрап-выборок обучается свой экземпляр одного и того же базового алгоритма (например, решающего дерева). Все модели обучаются независимо и параллельно.<br>3. <b>Aggregating (агрегация):</b><br>   - Для задачи <b>классификации</b> итоговое предсказание определяется большинством голосов (majority voting).<br>   - Для задачи <b>регрессии</b> итоговое предсказание — это среднее всех предсказаний.<br><b>Особенность:</b> Бэггинг наиболее эффективен для моделей, которые имеют низкое смещение, но высокий разброс (т.е. нестабильны и склонны к переобучению). Классический пример — глубокие решающие деревья. Бэггинг "успокаивает" такие модели, делая их более робастными. Случайный лес — это самый известный пример бэггинга.</p><p><b>Применение на практике:</b> <code>sklearn.ensemble.BaggingClassifier</code> и <code>BaggingRegressor</code>.</p>`,
          // Q64
          `<h3>Суть</h3><p>Бустинг — это метод ансамблирования, при котором модели строятся последовательно. Каждая новая модель в ансамбле фокусируется на исправлении ошибок, допущенных предыдущими моделями. Основная цель — уменьшить смещение (bias) модели.</p><h3>Подробное описание</h3><p><b>Бустинг (Boosting)</b> — это итеративный процесс построения сильного классификатора из набора "слабых" (моделей, которые работают лишь ненамного лучше случайного угадывания).<br><b>Общая схема:</b><br>1. Обучается первая простая модель на исходных данных.<br>2. Анализируются ошибки этой модели. Объектам, на которых модель ошиблась, придается больший вес.<br>3. Обучается вторая модель, которая уделяет больше внимания объектам с большими весами (то есть "трудным" объектам).<br>4. Процесс повторяется: каждая следующая модель концентрируется на ошибках предыдущего ансамбля.<br>5. Итоговое предсказание — это взвешенная сумма предсказаний всех построенных моделей.<br><b>Особенности:</b><br> - <b>Последовательное обучение:</b> Модели нельзя обучать параллельно, так как каждая зависит от предыдущей. Это делает бустинг медленнее бэггинга.<br> - <b>Уменьшение смещения:</b> Бустинг способен строить очень точные модели, которые хорошо улавливают сложные зависимости.<br> - <b>Склонность к переобучению:</b> Если строить слишком много моделей или использовать слишком сложные базовые модели, бустинг может переобучиться. Требует аккуратной настройки гиперпараметров.<br><b>Известные алгоритмы:</b> AdaBoost, Gradient Boosting.</p>`,
          // Q65
          `<h3>Суть</h3><p>Градиентный бустинг — это мощная разновидность бустинга, где каждая новая модель обучается предсказывать не сами ответы, а остатки (ошибки) предыдущего ансамбля. Современные реализации (XGBoost, LightGBM, CatBoost) являются одними из лучших алгоритмов для табличных данных.</p><h3>Подробное описание</h3><p><b>Градиентный бустинг (Gradient Boosting)</b> — это обобщение идеи бустинга. Вместо того чтобы на каждом шаге менять веса объектов, алгоритм строит новую модель так, чтобы она аппроксимировала антиградиент функции потерь предыдущего ансамбля. Говоря проще, каждая новая модель учится на ошибках (остатках) всей предыдущей композиции моделей: $h_m(x) \\approx y - \\sum_{i=1}^{m-1} h_i(x)$. В качестве базовых моделей почти всегда используются неглубокие решающие деревья.<br><b>Общая характеристика:</b> Это один из самых мощных и популярных алгоритмов для задач на структурированных (табличных) данных.<br><b>Современные реализации:</b> Стандартный градиентный бустинг в "sklearn" (<code>GradientBoostingClassifier</code>) достаточно медленный. Индустриальным стандартом стали его оптимизированные реализации:<br> - <b>XGBoost (eXtreme Gradient Boosting):</b> Долгое время был "королем" соревнований по ML. Включает в себя L1/L2 регуляризацию, эффективную параллельную обработку и умеет работать с пропусками.<br> - <b>LightGBM (Light Gradient Boosting Machine):</b> Разработка Microsoft. Главное преимущество — огромная скорость и меньшее потребление памяти. Использует "листовой" (leaf-wise) рост деревьев, что очень эффективно.<br> - <b>CatBoost (Categorical Boosting):</b> Разработка Яндекса. Главная особенность — превосходная встроенная обработка категориальных признаков, которая часто избавляет от необходимости делать One-Hot Encoding. Очень устойчив к переобучению и имеет хорошие настройки "из коробки".</p>`,
        ]

        const navList = document.querySelector("#questionNav ul")
        const contentDiv = document.getElementById("content")
        const searchInput = document.getElementById("searchInput")

        // --- 1. Генерация контента и навигации ---
        questions.forEach((q, i) => {
          const sectionId = `q${i + 1}`
          const linkText = `${q.split(".")[0]}. ${q.split(". ")[1]}`

          // Создание ссылки в навигации
          const li = document.createElement("li")
          li.innerHTML = `<a href="#${sectionId}" data-target-id="${sectionId}" class="block p-2 rounded-md hover:bg-violet-100 transition-colors duration-200">${linkText}</a>`
          navList.appendChild(li)

          // Создание секции с контентом
          const section = document.createElement("section")
          section.id = sectionId
          section.className =
            "content-section bg-white p-6 sm:p-8 rounded-2xl shadow-lg"
          section.innerHTML = `
                  <h2 class="text-2xl md:text-3xl font-bold mb-6 text-slate-900">${q}</h2>
                  ${
                    contents[i] ||
                    "<p>Ответ на данный вопрос скоро появится...</p>"
                  }
              `
          contentDiv.appendChild(section)
        })

        // --- 2. Функциональность поиска ---
        searchInput.addEventListener("input", () => {
          const filter = searchInput.value.toLowerCase()
          const navItems = navList.getElementsByTagName("li")
          for (let i = 0; i < navItems.length; i++) {
            const text = questions[i].toLowerCase()
            if (text.includes(filter)) {
              navItems[i].style.display = ""
            } else {
              navItems[i].style.display = "none"
            }
          }
        })

        // --- 3. Функциональность кнопки "Наверх" ---
        const scrollToTopBtn = document.getElementById("scrollToTopBtn")
        window.addEventListener("scroll", () => {
          scrollToTopBtn.classList.toggle("hidden", window.scrollY < 300)
        })

        scrollToTopBtn.addEventListener("click", () => {
          window.scrollTo({ top: 0 })
        })

        // --- 4. Подсветка активной ссылки в навигации при скролле ---
        const navLinks = document.querySelectorAll("#questionNav a")
        const contentSections = document.querySelectorAll(".content-section")

        const observerOptions = {
          root: null, // viewport
          rootMargin: "0px",
          threshold: 0.2, // секция считается активной, если видна на 20%
        }

        const observer = new IntersectionObserver((entries, observer) => {
          entries.forEach((entry) => {
            if (entry.isIntersecting) {
              const targetId = entry.target.id
              navLinks.forEach((link) => {
                link.classList.toggle(
                  "nav-active",
                  link.dataset.targetId === targetId
                )
              })
            }
          })
        }, observerOptions)

        contentSections.forEach((section) => {
          observer.observe(section)
        })

        // --- 5. Перерисовка математических формул после добавления контента ---
        if (window.MathJax && window.MathJax.startup) {
          window.MathJax.startup.promise
            .then(() => window.MathJax.typesetPromise())
            .catch((err) => console.error("MathJax typesetting failed: ", err))
        }
      })
    </script>
  </body>
</html>
